package Libraries.Compute.Statistics.Tests

use Libraries.Compute.Statistics.DataFrame
use Libraries.Compute.Statistics.DataFrameColumn
use Libraries.Compute.Statistics.Columns.TextColumn
use Libraries.Compute.Statistics.Columns.NumberColumn
use Libraries.Compute.Statistics.Inputs.ColumnInput
use Libraries.Compute.Statistics.Inputs.FactorInput
use Libraries.Compute.Statistics.Distributions.NormalDistribution
use Libraries.Compute.Statistics.Distributions.VarianceRatioDistribution
use Libraries.Compute.Statistics.Distributions.HeavyTailNormalDistribution
use Libraries.Compute.Statistics.Distributions.StudentizedRangeDistribution
use Libraries.Compute.Statistics.Distributions.ClassificationDistribution
use Libraries.Compute.Statistics.Calculations.Summarize
use Libraries.Compute.Statistics.Calculations.Mean
use Libraries.Compute.Statistics.Calculations.Variance
use Libraries.Compute.Statistics.Transforms.ConvertColumnsToRanksTransform
use Libraries.Compute.Statistics.Reporting.CompareVariancesResult
use Libraries.Compute.Statistics.Reporting.CompareDistributionsResult
use Libraries.Compute.Math
use Libraries.Containers.Array
use Libraries.Containers.HashTable
use Libraries.Containers.Iterator
use Libraries.Compute.Matrix
use Libraries.Compute.Statistics.Reporting.CompareMeansResult
use Libraries.Compute.Statistics.Reporting.CompareMeansSummary
use Libraries.Compute.Statistics.Transforms.TransformWider


/*
    This class implements several parametric and non-parametric tests:
    Parametric:
        CompareMeanTo is a One-Sample T-Test. 
        Difference between one group and a given mean
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test

        CompareTwoRelatedMeans is a Paired T-Test
        Difference between two paired groups and a given mean
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test 

        CompareTwoMeans is a Two-Sample T-Test
        Difference between two groups when groups have equal variances
        For more information: https://en.wikipedia.org/wiki/Student%27s_t-test

        CompareTwoMeans is a Welch's Two-Sample T-Test. 
        Difference between two groups when groups have unequal variances
        For more information: https://en.wikipedia.org/wiki/Welch%27s_t-test       

        CompareSeveralMeans is a Welch's (One-Way) Analysis Of Variance (ANOVA) 
        Difference between several groups on one dependent variable when groups have unequal variances with one independent variable
        For more information: https://en.wikipedia.org/wiki/One-way_analysis_of_variance

        CompareSeveralMeans is a Univariate Analysis Of Variance (ANOVA)
        Difference between several groups on one dependent variable when groups have equal variances with one or more independent variables
        For more information: https://en.wikipedia.org/wiki/Analysis_of_variance
        For more information: https://en.wikipedia.org/wiki/One-way_analysis_of_variance
        For more information: https://en.wikipedia.org/wiki/Two-way_analysis_of_variance
        For more information: https://www.statology.org/factorial-anova/

        CompareSeveralMeans is a Multivariate Analysis Of Variance (MANOVA). 
        Difference between several groups on more than one dependent variable with one or more independent variables
        For more information: https://en.wikipedia.org/wiki/Multivariate_analysis_of_variance 

        CompareSeveralRelatedMeans is a Repeated Measures Univariate Analysis Of Variance (RM ANOVA, Mixed ANOVA)
        Difference between several groups on one dependent variable when there are repeated measures
        For more information: https://en.wikipedia.org/wiki/Repeated_measures_design
        For more information: https://en.wikipedia.org/wiki/Mixed-design_analysis_of_variance

        ** Mixed MANOVA is NOT IMPLEMENTED YET **
        CompareSeveralRelatedMeans is a Repeated Measures Multivariate Analysis Of Variance (RM MANOVA, Mixed MANOVA)
        Difference between several groups on more than one dependent variable when there are repeated measures
        For more information: https://en.wikipedia.org/wiki/Repeated_measures_design
        For more information: https://en.wikipedia.org/wiki/Mixed-design_analysis_of_variance       

        ** NOT IMPLEMENTED YET **
        _____________ is a Univariate Analysis Of Covariance (ANCOVA)
        Difference between several groups while controlling for nuisance variables
        For more information: https://en.wikipedia.org/wiki/Analysis_of_covariance

        ** NOT IMPLEMENTED YET **
        _____________ is a Multivariate Analysis Of Covariance (MANCOVA)
        Difference between several groups while controlling for nuisance variables
        For more information: https://en.wikipedia.org/wiki/Multivariate_analysis_of_covariance

        ** NOT IMPLEMENTED YET **
        _____________ is a Repeated Measures Univariate Analysis Of Covariance (RM ANCOVA, Mixed ANCOVA)
        Difference between several groups while controlling for nuisance variables when there are repeated measures
        For more information: https://en.wikipedia.org/wiki/Analysis_of_covariance

        ** NOT IMPLEMENTED YET **
        _____________ is a Repeated Measures Multivariate Analysis Of Covariance (RM MANCOVA, Mixed MANCOVA)
        Difference between several groups while controlling for nuisance variables when there are repeated measures
        For more information: https://en.wikipedia.org/wiki/Multivariate_analysis_of_covariance

    Non-Parametric:
        CompareRankedMeanTo is a Wilcoxon Signed-Ranks Test
        Difference between one rank ordered group and a given median without assumptions about the distribution.
        For more information: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test

        CompareTwoRelatedRankedMeans is a Wilcoxon Signed-Ranks Test
        Difference between two rank ordered paired groups without assumptions about the distribution.
        For more information: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test

        CompareTwoRankedMeans is a Mann-Whitney U-Test aka Wilcoxon Rank-Sum Test
        Difference between two rank ordered groups without assumptions about the distribution
        For more information: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test
    
        CompareSeveralRelatedRankedMeans is a Friedman Test
        Difference between three or more rank ordered repeated measures groups without assumptions about the distribution
        For more information: https://en.wikipedia.org/wiki/Friedman_test

        CompareSeveralRankedMeans is a (One-Way) Kruskal-Wallis H Test
        Difference between three or more rank ordered groups without assumptions about the distribution
        For more information: https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance

        ** NOT IMPLEMENTED YET **
        _____________ is a Factorial (Multi-Way) Scheirer–Ray–Hare Test
        Difference between several rank ordered groups on multiple independent variables without assumptions about the distribution
        For more information: https://en.wikipedia.org/wiki/Scheirer%E2%80%93Ray%E2%80%93Hare_test

    This class was partially adapted from the same model in Apache Commons, but was expanded 
    upon to simplify the library and add a variety of helper actions that were missing.
    More information about this class can be found on its documentation pages for
    OneWayAnova, TTest, MannWhitneyUTest and WilcoxonSignedRankTest
    https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html

    Attribute: Author Andreas Stefik, Hannah Williams
    Attribute: Example

    use Libraries.Compute.Statistics.DataFrame
    use Libraries.Compute.Statistics.Tests.CompareMeans

    DataFrame frame
    frame:Load("Data/Data.csv")
    frame:AddSelectedColumnRange(0,3)
    CompareMeans compare = frame:CompareMeans()
    output compare:GetSummary()
*/
class CompareMeans is StatisticalTest
    private Math math
    private HeavyTailNormalDistribution tDistribution       // Distribution for 1 to 2 sample tests
    private NormalDistribution zdistribution                // Distribution for ranked 1 or 2 sample tests
    private VarianceRatioDistribution fDistribution         // Distribution for N sample tests
    private ClassificationDistribution x2distribution       // Distribution for ranked N sample tests
    private boolean defaultVarianceAssumption = true        // Default: true for N sample, false for 2 sample
    private boolean defaultDistributionAssumption = true    // Default: true for all
    private boolean userRequestedPairwise = false           // N sample tests

    private HashTable<text, DataFrame> groups       // Contain the dataframe objects for the most factored of the groups (i.e. the samples)
    private HashTable<text, Array<integer>> columnsAssociatedWithFactor // used in design matrix for N sample tests
    private HashTable<integer, Matrix> factorsAssociatedWithColumn      // binary encoded, used in design matrix for N sample tests
    private HashTable<integer, text> factorIndex    // Used to decode the groupings in multi-way comparisons 
    private Array<DataFrameColumn> factorLevels     // Used to compute the degrees of freedom in multi-way comparisons
    private Array<text> factorHeaders               // Used factor headers
    private Array<text> columnHeaders               // Used column headers
    private boolean multivariate = false            // Flag for multiple dependent variables
    private boolean factorial = false               // Flag for multiple independent factors
    private boolean balanced = true                 // Flag for equal sample sizes assumed to be true by default
    private boolean repeated = false                // Flag for paired or repeated measures tests
    private boolean parametric = true               // Flag for parametric tests
    private boolean type1 = false                   // Flag for type I SumOfSquares calculations *NOT IMPLEMENTED YET*
    private boolean type2 = true                    // Flag for type II SumOfSquares calculations
    private boolean type3 = false                   // Flag for type III SumOfSquares calculations *NOT IMPLEMENTED YET*

    private boolean needToSelectTest = true         // Flag to let this class auto-select a test based on given data
    private boolean needToProcessData = true        // Flag to let tell this class to process the selected data
    private integer numberOfFactors = 0             // Number of factors selected
    private integer numberOfColumns = 0             // Number of columns selected
    private integer totalObservations = 0           // Total observations (total sample size)
    private ExperimentalDesign design               // Object to hold and process various selections and data formats

    // USER CONTROLS
    boolean ranked = false                          // The sample observations are to be ranked

    // ASSUMPTION USER CONTROLS
    boolean assumeEqualVariances = false            // Calculations are to assume variances are equal 
    boolean assumeNormalDistribution = false        // Calculations are to assume normal distribution 
    boolean testVarianceAssumption = false          // Requested to test variance assumptions 
    boolean testDistributionAssumption = false      // Requested to test distribution assumptions 

    // PAIRWISE USER CONTROLS
    boolean correctFamilyWiseError = true           // Family-wise correction is applied in N-sample pairwise tests 
    boolean correctContinuityError = true           // For now, this is always true since we use normal approximation in ranked tests
    boolean useStrictCorrection = false             // Procedure to be applied in N-sample pairwise tests (corrects for p-value using Bonferroni correction)
    boolean useLenientCorrection = true             // Procedure to be applied in N-sample pairwise tests (corrects for p-value inherently)
    boolean useFittedApproach = true                // Conducts comparisons using the several-sample test results and estimated marginal means
    boolean useUnfittedApproach = true              // Conducts comparisons using individual pariwise two-sample tests

    number userMean = 0
    number userMedian = 0

    private DataFrame designFrame = undefined
    private Matrix designMatrix = undefined

    // The results of this test
    Array <CompareMeansResult> results

    action Calculate(DataFrame frame) 
        columnsAssociatedWithFactor:Empty()
        factorsAssociatedWithColumn:Empty()
        factorIndex:Empty()
        factorLevels:Empty()
        results:Empty()
        groups:Empty()
        factorHeaders:Empty()
        columnHeaders:Empty()
        
        if design:GetDesignFrame() = undefined
            design:RepeatedMeasures(repeated)
            design:Transform(frame)
        end 
        designFrame = design:GetDesignFrame()
        repeated = design:RepeatedMeasures() // This will override the boolean if a within factor is or isn't specified.

        numberOfFactors = design:GetBetweenSubjectsFactors():GetSize() + design:GetWithinSubjectsFactors():GetSize()
        numberOfColumns = design:GetDependentVariables():GetSize()

        if numberOfFactors > 0 and numberOfColumns > 1
            multivariate = true
        else
            multivariate = false
        end

        if numberOfFactors > 1
            factorial = true
        else
            factorial = false
        end

        // Copy the frame keeping only the selected factors/columns and reselect them
        // Anything else will be dropped for this computation.
        // No need to remove undefined values unless using a factor
        DataFrame cleanedFrame = designFrame:Copy()
        if multivariate
            cleanedFrame = designFrame:RemoveUndefinedRowsFromSelectedColumns()
        end
        DataFrame copy
        integer index = 0
        i = 0
        repeat while i < designFrame:GetSelectedFactorSize()
            DataFrameColumn factor = cleanedFrame:GetColumn(designFrame:GetSelection():GetFactor(i))
            if factor:GetHeader() = design:GetSubjectIdentifier()
                copy:AddColumn(factor)
                copy:AddSelectedFactor(index)
    
                DataFrameColumn levels = factor:Copy(true,true)
                factorIndex:Add(i, factor:GetHeader())
                factorLevels:Add(levels)
                factorHeaders:Add(factor:GetHeader())
                index = index + 1
            else
                copy:AddColumn(factor)
                copy:AddSelectedFactor(index)
    
                DataFrameColumn levels = factor:Copy(true,true)
                factorIndex:Add(i, factor:GetHeader())
                factorLevels:Add(levels)
                factorHeaders:Add(factor:GetHeader())
                index = index + 1
            end
            i = i + 1
        end

        i = 0
        repeat while i < designFrame:GetSelectedColumnSize()
            DataFrameColumn column = cleanedFrame:GetColumn(designFrame:GetSelection():GetColumn(i))
            copy:AddColumn(column)
            copy:AddSelectedColumn(index)
            if i = 0
                totalObservations = column:GetSize()
            else
                if numberOfFactors = 0
                    totalObservations = totalObservations + column:GetSize()
                else
                    if totalObservations < column:GetSize()
                        totalObservations = column:GetSize()
                    end
                end
            end
            columnHeaders:Add(column:GetHeader())
            index = index + 1
            i = i + 1
        end

        // Copy the selection to test for easier access 
        CopySelection(copy)


        // Check the data for missing data or incorrect column types
        CheckDataIntegrity(copy)


        // Collect data for each possible group (ignoring ID factor when repeated)
        if repeated
            DataFrame removeID = copy:Copy()
            i = 0
            repeat while i < copy:GetSelectedFactorSize()
                removeID:AddSelectedFactor(copy:GetSelection():GetFactor(i))
                i = i + 1
            end  
            i = 0
            repeat while i < copy:GetSelectedColumnSize()
                removeID:AddSelectedColumn(copy:GetSelection():GetColumn(i))
                i = i + 1
            end
            removeID:RemoveSelectedFactors(design:GetSubjectIdentifier())
            groups = GetGroups(removeID)
        else
            groups = GetGroups(copy)
        end

        // Check if samples are equal size
        balanced = CheckIfBalanced()

        if needToSelectTest
            designFrame = copy
            RunTest(copy)
        else
            designFrame = copy
        end

        needToProcessData = false
    end

    private action RunTest(DataFrame frame)
        needToProcessData = false
        parametric = (assumeNormalDistribution or defaultDistributionAssumption) and not ranked
        integer numberOfSamples = groups:GetSize()

        if numberOfSamples < 1
            alert("A CompareMeans calculation must include at least one sample.")
        end

        if parametric
            if numberOfSamples = 1
                CompareToMean(frame)
            elseif numberOfSamples = 2
                defaultVarianceAssumption = false
                if repeated
                    CompareTwoRelatedMeans(frame)
                else
                    CompareTwoMeans(frame)
                end
            else
                if repeated
                    CompareSeveralRelatedMeans(frame)
                else
                    CompareSeveralMeans(frame)
                end
            end
        else // non-parametric
            if numberOfSamples = 1
                CompareToRankedMean(frame)
            elseif numberOfSamples = 2
                if repeated
                    CompareTwoRelatedRankedMeans(frame)
                else
                    CompareTwoRankedMeans(frame)
                end
            else
                if factorial
                    if repeated
                        // Extension of Freidman Test
                        alert("A nonparametric factorial repeated measures CompareMeans test is not supported yet.")
                    else
                        // Multi-Way (Factorial) Scheirer–Ray–Hare Test
                        alert("A nonparametric factorial CompareMeans test is not supported yet. Formal Test Name: Scheirer–Ray–Hare Test")
                    end
                else
                    if repeated
                        CompareSeveralRelatedRankedMeans(frame)
                    else
                        CompareSeveralRankedMeans(frame)
                    end
                end
            end
        end 
    end

    /* 
        This is a one-sample t-test against a given mean (default is 0)

        Null hypothesis: The population mean is equal to a proposed mean
        Alternative hypothesis: The population mean is not equal to a proposed mean

        Assumptions:
            1. One sample:
                If more than one sample: Use a Paired T-Test        > CompareMeans:CompareTwoRelatedMeans

            2. Sample is normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Wilcoxon Signed-Ranks Test     > CompareMeans:CompareToRankedMean
        
        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumn(0)

        CompareMeans compare = frame:CompareToMean(10)
        output compare:GetSummary()
    */
    action CompareToMean(DataFrame frame)
        repeated = false
        ranked = false
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 1
            alert("CompareToMean must have at least one sample.")
        end

        if multivariate
            // One Sample Hotelling's T-Square Test
            alert("A parametric multivariate one-sample CompareMeans test is not supported yet. Formal Test Name: One Sample Hotelling's T-Square Test")
        else
            // One Sample T-Test
            Array<text> groupsArray = groups:CopyToKeyArray()
            integer i = 0
            repeat while i < groupsArray:GetSize()
                text groupText = groupsArray:Get(i)

                DataFrame groupFrame = groups:GetValue(groupText)
                groupFrame:SelectAllColumns()
                number mean = groupFrame:Mean()
                number variance = groupFrame:Variance()
                number size = groupFrame:GetColumn(0):GetSize()
                if size < 2
                    alert("Samples must have 2 or more observations. Not enough data for a comparison to be calculated.")
                end
                number cohensD = (mean - userMean) / math:SquareRoot(variance)
                number t = (mean - userMean) / (math:SquareRoot(variance / size))
                number df = size - 1
                tDistribution:Setup(df)
                number p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
    
                // Save the result
                CompareMeansResult result
                result:EqualVariances(true)
                result:NormalDistribution(true)
                result:SetSignificanceLevel(GetSignificanceLevel())
                result:SetFormat(GetStatisticalFormatting())
                result:SetTestStatistic(groupText,"t", t)
                result:SetEffectSize(groupText,"Cohen's d",cohensD)
                result:SetDegreesOfFreedom(groupText,"t", df)
                result:SetProbabilityValue(groupText,"t", p)
                result:SetInformation(groupText,"mean", mean)
                result:SetInformation(groupText,"variance", variance)
                result:SetInformation(groupText,"size", size)
                result:SetInformation("proposed","mean", userMean)
                result:SetFormalTestName("One Sample t-test")
                result:SetGroupsFrame(groupFrame)
                result:SetFactors(factorHeaders)
                result:SetColumns(columnHeaders)
                if testDistributionAssumption
                    // Check normality with Shapiro-Wilk's CompareDistributions Test
                    CompareDistributions compare
                    compare:SetSignificanceLevel(GetSignificanceLevel())
                    compare:SetStatisticalFormatting(GetStatisticalFormatting())
                    compare:CompareDistributionToNormal(groupFrame)
                    result:SetDistributionResults(compare:GetResults())
                end
                results:Add(result)
                i = i + 1
            end
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /*
        This action represents a two sample paired t-test.

        Null hypothesis: The difference mean is equal to a proposed mean
        Alternative hypothesis: The difference mean is not equal to a proposed mean

        Assumptions:
            1. Two samples:
                If more than two samples: Use a Repeated Measures Anova > CompareMeans:CompareSeveralRelatedMeans

            2. Samples are dependent:
                If not dependent: Use a Two-Sample T-Test               > CompareMeans:CompareTwoMeans

            3. Difference between samples is normally distributed:
                To test this: Use a Shapiro-Wilk test                   > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Wilcoxon Signed-Ranks Test         > CompareMeans:CompareTwoRelatedRankedMeans

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumn(0)
        frame:AddSelectedColumn(1)

        CompareMeans compare = frame:CompareRelatedMeans(10)
        output compare:GetSummary()
    */
    action CompareTwoRelatedMeans(DataFrame frame)
        repeated = true
        ranked = false
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 2
            alert("CompareTwoRelatedMeans must have at least two samples.")
        end

        if multivariate
            // Paired Hotelling's T-Square Test
            alert("A multivariate paired sample CompareMeans test is not supported yet. Formal Test Name: Paired Sample Hotelling's T-Square Test")
        else
            // Paired Sample T-Test
            Array<text> groupsArray = groups:CopyToKeyArray()
            integer i = 0
            repeat while i < groupsArray:GetSize()
                integer j = i + 1
                repeat while j < groupsArray:GetSize()
                    text group1Text = groupsArray:Get(i)
                    text group2Text = groupsArray:Get(j)
                    text combo = group1Text+"_"+group2Text

                    DataFrameColumn left = groups:GetValue(group1Text):GetColumn(0)
                    left:SetHeader(group1Text)
                    DataFrameColumn right = groups:GetValue(group2Text):GetColumn(0)
                    right:SetHeader(group2Text)

                    // Paired data should be the same size
                    if left:GetSize() not= right:GetSize()
                        alert("Samples must be the same size for a paired design. " + left:GetHeader() + " is a different size than "+ right:GetHeader() + ".")
                    end
                    if left:GetSize() < 2 or right:GetSize() < 2
                        alert("Samples must have 2 or more observations. Not enough data for a comparison to be calculated.")
                    end

                    DataFrame groupFrame
                    groupFrame:AddColumn(left)
                    groupFrame:AddColumn(right)

                    // Calculate the test statistics
                    Summarize summarizeL
                    left:Calculate(summarizeL)
                    number mean1 = summarizeL:GetMean()
                    number var1 = summarizeL:GetVariance()
                    number size1 = left:GetSize()

                    Summarize summarizeR
                    right:Calculate(summarizeR)
                    number mean2 = summarizeR:GetMean()
                    number var2 = summarizeR:GetVariance()
                    number size2 = right:GetSize()
   
                    // Create difference column/frame
                    NumberColumn numLeft = left:ConvertToNumberColumn()
                    NumberColumn numRight = right:ConvertToNumberColumn()
                    NumberColumn difference = numLeft:Subtract(numRight)
                    difference:SetHeader("difference")
                    DataFrame diffFrame
                    diffFrame:AddColumn(difference)
                    diffFrame:SelectAllColumns()
                    number diffMean = diffFrame:Mean()
                    number diffVar = diffFrame:Variance()

                    // Run a one-sample t-test on the difference
                    CompareMeans compare1
                    compare1:SetMean(userMean)
                    compare1:CompareToMean(diffFrame)
                    CompareMeansResult res = compare1:GetResult()
                    text statName = res:GetTestStatisticName()

                    // Save the result
                    CompareMeansResult result
                    result:EqualVariances(true) 
                    result:NormalDistribution(true)
                    result:Repeated(true)
                    result:SetSignificanceLevel(GetSignificanceLevel())
                    result:SetFormat(GetStatisticalFormatting())
                    result:SetTestStatistic(combo, statName, res:GetTestStatistic())
                    result:SetEffectSize(combo, res:GetEffectSizeName(),res:GetEffectSize())
                    result:SetDegreesOfFreedom(combo, statName, res:GetDegreesOfFreedom())
                    result:SetProbabilityValue(combo, statName, res:GetProbabilityValue())
                    result:SetInformation(group1Text,"mean", mean1)
                    result:SetInformation(group1Text,"variance", var1)
                    result:SetInformation(group1Text,"size", size1)
                    result:SetInformation(group2Text,"mean", mean2)
                    result:SetInformation(group2Text,"variance", var2)
                    result:SetInformation(group2Text,"size", size2)
                    result:SetInformation("difference","mean", diffMean)
                    result:SetInformation("difference","variance", diffVar)
                    result:SetInformation("proposed","mean", userMean)
                    result:SetFormalTestName("Paired t-test")
                    result:SetGroupsFrame(groupFrame)
                    result:SetFactors(factorHeaders)
                    result:SetColumns(columnHeaders)
                    if testDistributionAssumption
                        // Check normality with Shapiro-Wilk's CompareDistributions Test
                        CompareDistributions compare
                        compare:SetSignificanceLevel(GetSignificanceLevel())
                        compare:SetStatisticalFormatting(GetStatisticalFormatting())
                        compare:CompareDistributionToNormal(diffFrame)
                        result:SetDistributionResults(compare:GetResults())
                    end
                    results:Add(result)
                    j = j + 1
                end
                i = i + 1
            end
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /*
        This action represents a two sample t-test on two columns of data.

        Null hypothesis: The two means are equal
        Alternative hypothesis: The two means are not equal

        Assumptions:
            1. Two samples:
                If more than two samples: Use a One-Way Anova       > CompareMeans:CompareSeveralMeans
              
            2. Samples are independent:
                If not independent: Use a Paired T-Test             > CompareMeans:CompareTwoRelatedMeans

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Mann-Whitney U-Test            > CompareMeans:CompareTwoRankedMeans

            4. Samples have equal variances:
                To test this: Use a Levene's Test                   > CompareVariances:CompareIndependentVariances
                If not equal: Use Welch's T-Test                    > CompareMeans:AssumeEqualVariances(false)

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumn(0)
        frame:AddSelectedColumn(1)
        CompareMeans compare = frame:CompareMeans()
        output compare:GetSummary()
    */
    action CompareTwoMeans(DataFrame frame)
        repeated = false
        ranked = false
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 2
            alert("CompareTwoMeans must have at least two samples.")
        end

        if multivariate
            // Two Sample Hotelling's T-Square Test Possibly MANOVA
            //alert("A multivariate two sample CompareMeans test is not supported yet. Formal Test Name: Two Sample Hotelling's T-Square Test")
            defaultVarianceAssumption = true
            CompareSeveralMeans(frame)
        elseif factorial
            //alert("A factorial two sample CompareMeans test is not supported yet.")
            defaultVarianceAssumption = true
            CompareSeveralMeans(frame)            
        else
            // Two Sample T-Test
            Array<text> groupsArray = groups:CopyToKeyArray()
            integer i = 0
            repeat while i < groupsArray:GetSize()
                integer j = i + 1
                repeat while j < groupsArray:GetSize()
                    text group1Text = groupsArray:Get(i)
                    text group2Text = groupsArray:Get(j)
                    text combo = group1Text+"_"+group2Text
    
                    DataFrameColumn left = groups:GetValue(group1Text):GetColumn(0)
                    left:SetHeader(group1Text)
                    DataFrameColumn right = groups:GetValue(group2Text):GetColumn(0)
                    right:SetHeader(group2Text)

                    if left:GetSize() < 2 or right:GetSize() < 2
                        alert("Samples must have 2 or more observations. Not enough data for a comparison to be calculated.")
                    end

                    DataFrame groupFrame
                    groupFrame:AddColumn(left)
                    groupFrame:AddColumn(right)
                    groupFrame:SelectAllColumns()

                    // Calculate the test statistics
                    Summarize summarizeL
                    left:Calculate(summarizeL)
                    number mean1 = summarizeL:GetMean()
                    number var1 = summarizeL:GetVariance()
                    number size1 = left:GetSize()

                    Summarize summarizeR
                    right:Calculate(summarizeR)
                    number mean2 = summarizeR:GetMean()
                    number var2 = summarizeR:GetVariance()
                    number size2 = right:GetSize()

                    text testname = ""
                    number t = 0
                    number df = 0
                    if assumeEqualVariances or defaultVarianceAssumption
                        number pooledVar = ((size1  - 1) * var1 + (size2 - 1) * var2 ) / (size1 + size2 - 2)
                        t = (mean1 - mean2) / (math:SquareRoot(pooledVar * ((1 / size1) + (1 / size2))))
                        df = size1 + size2 - 2
                        testname = "Two Sample t-test"
                    else
                        t = (mean1 - mean2) / (math:SquareRoot((var1 / size1) + (var2 / size2)))
                        df = DegreesOfFreedom(var1, var2, size1, size2)
                        testname = "Welch Two Sample t-test"
                    end
                    tDistribution:Setup(df)
                    number p = 2.0 * tDistribution:CumulativeDistribution(-math:AbsoluteValue(t))
                    number cohensD = (mean1 - mean2) / math:SquareRoot((var1 + var2) / 2.0)

                    // Save the result
                    CompareMeansResult result
                    result:EqualVariances(assumeEqualVariances or defaultVarianceAssumption) 
                    result:NormalDistribution(true)
                    result:SetSignificanceLevel(GetSignificanceLevel())
                    result:SetFormat(GetStatisticalFormatting())
                    result:SetTestStatistic(combo, "t", t)
                    result:SetEffectSize(combo, "Cohen's d", cohensD)
                    result:SetDegreesOfFreedom(combo, "t", df)
                    result:SetProbabilityValue(combo, "t", p)
                    result:SetInformation(group1Text,"mean", mean1)
                    result:SetInformation(group1Text,"variance", var1)
                    result:SetInformation(group1Text,"size", size1)
                    result:SetInformation(group2Text,"mean", mean2)
                    result:SetInformation(group2Text,"variance", var2)
                    result:SetInformation(group2Text,"size", size2)
                    result:SetFormalTestName(testname)
                    result:SetGroupsFrame(groupFrame)
                    result:SetFactors(factorHeaders)
                    result:SetColumns(columnHeaders)
                    if testDistributionAssumption   
                        // Check normality using a Shapiro-Wilk's CompareDistributions Test
                        CompareDistributions compare
                        compare:SetSignificanceLevel(GetSignificanceLevel())
                        compare:SetStatisticalFormatting(GetStatisticalFormatting())
                        compare:CompareDistributionToNormal(groupFrame)
                        result:SetDistributionResults(compare:GetResults())
                    end
                    if testVarianceAssumption
                        // Check equality of variance using a Levene's CompareVariances test 
                        CompareVariances compare
                        compare:SetSignificanceLevel(GetSignificanceLevel())
                        compare:SetStatisticalFormatting(GetStatisticalFormatting())
                        compare:Calculate(groupFrame)
                        result:SetVarianceResult(compare:GetResult())
                    end
                    results:Add(result)
                    j = j + 1
                end
                i = i + 1
            end
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Repeated measures analysis of variance (ANOVA) for 3 or more dependent groups.
        This action assumes each row in the data set is an individual subject and calculates  

        Null hypothesis: The means are equal across all samples.
        Alternative hypothesis: At least one mean is not equal to the others.

        Assumptions:
            1. Two or more samples:
                If two samples: Best to use a Paired T-Test         > CompareMeans:CompareTwoRelatedMeans
              
            2. Samples are dependent:
                If not dependent: Use a One-Way Anova               > CompareMeans:CompareSeveralMeans

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Friedman Test                  > CompareMeans:CompareSeveralRelatedRankedMeans

            4. Difference between samples have equal variances:
                To test this: Use a Mauchly's Test                  > CompareVariances:CompareDependentVariances
                If not equal: Use Greenhouse-Geisser correction     > CompareMeans:AssumeEqualVariances(false)

        Post-Hoc Analysis:
            If this test is significant it may help to run a post hoc follow-up test
            This can be done using a CompareMeansPairwise test and passing the result from this test as the parameter
                Use a Bonferroni Pairwise Procedure                 > CompareMeansPairwise > UseStrictCorrection(true)

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumnRange(0,4)
        CompareMeans compare = frame:CompareRelatedMeans()
        output compare:GetSummary()
    */
    action CompareSeveralRelatedMeans(DataFrame frame)
        repeated = true
        ranked = false
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            Calculate(frame)
        end
        boolean betweenDesign = design:GetBetweenSubjectsFactors():GetSize() > 0
        boolean withinDesign = design:GetWithinSubjectsFactors():GetSize() > 0
        boolean mixedDesign = betweenDesign and withinDesign

        if mixedDesign
            if multivariate
                alert("A multivariate mixed design CompareMeans test is not currently supported.")
            else
                // If it's mixed design:
                // run within-subjects factors only (with id)
                // run between-subjects and within-subjects factors (without id)
                // update error terms ss and df by subtracting factors and interactions 
                // compute statistics
                DataFrame newFrame = designFrame:Copy()
    
                // Within Subjects ANOVA
                ExperimentalDesign wDesign
                if design:GetSubjectIdentifier() not= "" // Add Subject Factor
                    wDesign:AddSubjectIdentifier(design:GetSubjectIdentifier())
                end
                i = 0 // Add Within Factors
                repeat while i < design:GetWithinSubjectsFactors():GetSize()
                    wDesign:AddWithinSubjectsFactor(design:GetWithinSubjectsFactors():Get(i))
                    i = i + 1
                end
                i = 0 // Add Dependent Variables
                repeat while i < design:GetDependentVariables():GetSize()
                    wDesign:AddDependentVariable(design:GetDependentVariables():Get(i))
                    i = i + 1
                end
                CompareMeans within
                within:SetExperimentalDesign(wDesign)
                within:Calculate(newFrame)
                CompareMeansResult withinResult = within:GetResult()

                // Mauchly's Test
                CompareVariancesResult vResult
                if testVarianceAssumption
                    // Mauchly's test of sphericity
                    ExperimentalDesign mDesign = wDesign:Copy()
                    i = 0 // Add Between Factors For Correct Design Matrix Creation
                    repeat while i < design:GetBetweenSubjectsFactors():GetSize()
                        mDesign:AddBetweenSubjectsFactor(design:GetBetweenSubjectsFactors():Get(i))
                        i = i + 1
                    end
                    CompareVariances mauchly
                    mauchly:SetExperimentalDesign(mDesign)
                    mauchly:Calculate(newFrame)
                    vResult = mauchly:GetResult()
                end

                // Between Subjects ANOVA
                ExperimentalDesign bDesign
                i = 0 // Add Between Factors
                repeat while i < design:GetBetweenSubjectsFactors():GetSize()
                    bDesign:AddBetweenSubjectsFactor(design:GetBetweenSubjectsFactors():Get(i))
                    i = i + 1
                end
                i = 0 // Add Within Factors as Between Factors
                repeat while i < design:GetWithinSubjectsFactors():GetSize()
                    bDesign:AddBetweenSubjectsFactor(design:GetWithinSubjectsFactors():Get(i))
                    i = i + 1
                end
                i = 0 // Add Dependent Variables
                repeat while i < design:GetDependentVariables():GetSize()
                    bDesign:AddDependentVariable(design:GetDependentVariables():Get(i))
                    i = i + 1
                end
                CompareMeans between
                between:SetExperimentalDesign(bDesign)
                between:Calculate(newFrame)
                CompareMeansResult betweenResult = between:GetResult()
    
                HashTable<text, number> ssFactors   // univariate
                HashTable<text, Matrix> sscpFactors // multivariate
                HashTable<text, number> dfFactors 
    
                Matrix sscpResiduals
                number ssResiduals = 0
                number dfResiduals = 0

                HashTable<text, number> ssErrors
                HashTable<text, number> dfErrors
                HashTable<text, text> factorToError // Links each factor to the error term to be used in statistic computation
                
                Array<text> withinSources = withinResult:GetSources()
                Array<text> betweenSources = betweenResult:GetSources()

                // Get initial error terms using within anova
                i = 0 
                repeat while i < withinSources:GetSize()
                    text source = withinSources:Get(i)
                    HashTable<text, number> info = withinResult:GetInformation():GetValue(source)
                    if info:HasKey("error ss")
                        ssErrors:Add(source, info:GetValue("error ss")+info:GetValue("ss"))
                        dfErrors:Add(source, info:GetValue("error df")+info:GetValue("df"))            
                    end
                    if source = design:GetSubjectIdentifier()
                        ssErrors:Add(source, info:GetValue("ss"))
                        dfErrors:Add(source, info:GetValue("df")) 
                    end
                    i = i + 1
                end
    
                // Update error terms using between anova
                i = 0 
                repeat while i < betweenSources:GetSize()
                    text source = betweenSources:Get(i)
                    HashTable<text, number> info = betweenResult:GetInformation():GetValue(source)
                    if info:HasKey("error ss")
                        if not factorToError:HasKey(source)
                            factorToError:Add(source, UpdateAndGetErrorTerm(ssErrors, dfErrors, source, info:GetValue("ss"),  info:GetValue("df"))) 
                        end       
                    end
                    i = i + 1
                end 

                // Compute the total sum of squares and total variance (error)
                Array<text> errors = ssErrors:CopyToKeyArray()
                number ssSubjects = 0 
                number dfSubjects = 0
                number ssTotalError = betweenResult:GetInformation():GetValue("Residual Error"):GetValue("ss") 
                number dfTotalError = betweenResult:GetInformation():GetValue("Residual Error"):GetValue("df")     
                number ssTotal = ssTotalError 
                number dfTotal = dfTotalError  
                i = 0 
                repeat while i < withinSources:GetSize()
                    text source = withinSources:Get(i)
                    HashTable<text, number> info = withinResult:GetInformation():GetValue(source)
                    if info:HasKey("error ss") and not dfFactors:HasKey(source)
                        ssTotal = ssTotal + info:GetValue("ss")
                        dfTotal = dfTotal + info:GetValue("df")
                    end
                    i = i + 1
                end    

                i = 0 
                repeat while i < betweenSources:GetSize()
                    text source = betweenSources:Get(i)
                    if not withinResult:GetInformation():HasKey(source)
                        HashTable<text, number> info = betweenResult:GetInformation():GetValue(source)
                        if info:HasKey("error ss") and not dfFactors:HasKey(source) and factorToError:HasKey(source)
                            if i = 0
                                ssSubjects = ssErrors:GetValue(factorToError:GetValue(source))
                                dfSubjects = dfErrors:GetValue(factorToError:GetValue(source))
                            end
                            ssTotal = ssTotal + info:GetValue("ss")
                            dfTotal = dfTotal + info:GetValue("df")
                        end
                    end
                    i = i + 1
                end                              

                boolean significantWithin = false
                boolean significantBetween = false
                number numberOfObservations = design:GetNumberOfObservations()
                CompareMeansResult result
                Array<text> sources
                // Compute statistics and save results
                i = 0 
                repeat while i < withinSources:GetSize()
                    text source = withinSources:Get(i)
                    HashTable<text, number> info = withinResult:GetInformation():GetValue(source)
                    if info:HasKey("error ss") and not dfFactors:HasKey(source)
                        number ssFactor = info:GetValue("ss")
                        number dfFactor = info:GetValue("df")
                        ssResiduals = ssErrors:GetValue(source)
                        dfResiduals = dfErrors:GetValue(source)   
    
                        number meanSSFactor = ssFactor / dfFactor
                        number meanSSResiduals = ssResiduals / dfResiduals
                        fDistribution:Setup(dfFactor, dfResiduals)
                        number f = meanSSFactor / meanSSResiduals
                        number p = 1.0 - fDistribution:CumulativeDistribution(f)
                        if p <= GetSignificanceLevel()
                            significantWithin = true
                        end
                        
                        number factorVariation = (ssFactor - dfFactor * meanSSResiduals)
                        // ANOVA effect size equations see: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                        number eta_squared = ssFactor / ssTotal
                        number partial_eta_squared = ssFactor / (ssFactor + ssResiduals)
                        number generalized_eta_squared = ssFactor / (ssFactor + ssTotalError)

                        // See: https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
                        number omega_squared = factorVariation / (ssTotal + (ssSubjects / dfSubjects))
                        number partial_omega_squared = factorVariation / (ssFactor + ssResiduals + ssSubjects + (ssSubjects / dfSubjects))
                        number generalized_omega_squared = factorVariation / (factorVariation + numberOfObservations * (ssTotalError / dfTotalError))

                        sources:Add(source)
                        result:SetTestStatistic(source, "F", f)
                        result:SetDegreesOfFreedom(source, "F", dfFactor)
                        result:SetProbabilityValue(source, "F", p)
                        result:SetInformation(source, "F", f)
                        result:SetInformation(source, "p", p)
                        result:SetInformation(source, "ss", ssFactor)
                        result:SetInformation(source, "df", dfFactor)
                        result:SetInformation(source, "meanss", meanSSFactor)
                        result:SetInformation(source, "error ss", ssResiduals)
                        result:SetInformation(source, "error df", dfResiduals)
                        result:SetInformation(source, "eta-squared", eta_squared)
                        result:SetInformation(source, "partial-eta-squared", partial_eta_squared)
                        result:SetInformation(source, "generalized-eta-squared", generalized_eta_squared)
                        result:SetInformation(source, "omega-squared", omega_squared)
                        result:SetInformation(source, "partial-omega-squared", partial_omega_squared)
                        result:SetInformation(source, "generalized-omega-squared", generalized_omega_squared)

                        // Add sphericity correction info
                        if vResult:GetInformation():HasKey(source) and vResult:GetInformation():GetValue(source):HasKey("p")
                            number pval = vResult:GetInformation():GetValue(source):GetValue("p")
                            result:SetInformation(source,"sphericity p", pval)
        
                            number dfn = result:GetInformation():GetValue(source):GetValue("df")
                            number dfd = result:GetInformation():GetValue(source):GetValue("error df")
        
                            number ggcorrection = vResult:GetInformation():GetValue(source):GetValue("gg")
                            fDistribution:Setup(ggcorrection*dfn, ggcorrection*dfd)
                            number ggp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                            result:SetInformation(source,"gg", ggcorrection)
                            result:SetInformation(source,"gg p", ggp)
        
                            number hfcorrection = vResult:GetInformation():GetValue(source):GetValue("hf")
                            fDistribution:Setup(hfcorrection*dfn, hfcorrection*dfd)
                            number hfp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                            result:SetInformation(source,"hf", hfcorrection)
                            result:SetInformation(source,"hf p", hfp)
                        end

                        if factorial
                            result:SetEffectSize(source, "partial-eta-squared", partial_eta_squared)
                        else
                            result:SetEffectSize(source, "eta-squared", eta_squared)
                        end      
                    end
                    i = i + 1
                end
    
                i = 0 
                repeat while i < betweenSources:GetSize()
                    text source = betweenSources:Get(i)
                    if not withinResult:GetInformation():HasKey(source)
                        HashTable<text, number> info = betweenResult:GetInformation():GetValue(source)
                        if info:HasKey("error ss") and not dfFactors:HasKey(source) and factorToError:HasKey(source)
                            number ssFactor = info:GetValue("ss")
                            number dfFactor = info:GetValue("df")
                            ssResiduals = ssErrors:GetValue(factorToError:GetValue(source))
                            dfResiduals = dfErrors:GetValue(factorToError:GetValue(source)) 
    
                            number meanSSFactor = ssFactor / dfFactor
                            number meanSSResiduals = ssResiduals / dfResiduals
                            fDistribution:Setup(dfFactor, dfResiduals)
                            number f = meanSSFactor / meanSSResiduals
                            number p = 1.0 - fDistribution:CumulativeDistribution(f)
                            if p <= GetSignificanceLevel()
                                significantBetween = true
                            end
                        
                            number factorVariation = (ssFactor - dfFactor * meanSSResiduals)
                            // ANOVA effect size equations see: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            number eta_squared = ssFactor / ssTotal
                            number partial_eta_squared = ssFactor / (ssFactor + ssResiduals)
                            number generalized_eta_squared = ssFactor / (ssFactor + ssTotalError)
    
                            // See: https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
                            number omega_squared = factorVariation / (ssTotal + (ssSubjects / dfSubjects))
                            number partial_omega_squared = factorVariation / (ssFactor + ssSubjects + (ssSubjects / dfSubjects))
                            number generalized_omega_squared = factorVariation / (factorVariation + numberOfObservations * (ssTotalError / dfTotalError))

                            sources:Add(source)
                            result:SetTestStatistic(source, "F", f)
                            result:SetDegreesOfFreedom(source, "F", dfFactor)
                            result:SetProbabilityValue(source, "F", p)
                            result:SetInformation(source, "F", f)
                            result:SetInformation(source, "p", p)
                            result:SetInformation(source, "ss", ssFactor)
                            result:SetInformation(source, "df", dfFactor)
                            result:SetInformation(source, "meanss", meanSSFactor)
                            result:SetInformation(source, "error ss", ssResiduals)
                            result:SetInformation(source, "error df", dfResiduals)
                            result:SetInformation(source, "eta-squared", eta_squared)
                            result:SetInformation(source, "partial-eta-squared", partial_eta_squared)
                            result:SetInformation(source, "generalized-eta-squared", generalized_eta_squared)
                            result:SetInformation(source, "omega-squared", omega_squared)
                            result:SetInformation(source, "partial-omega-squared", partial_omega_squared)
                            result:SetInformation(source, "generalized-omega-squared", generalized_omega_squared)

                            // Add sphericity correction info where appropriate
                            text errorSource = factorToError:GetValue(source)
                            if vResult:GetInformation():HasKey(errorSource) and vResult:GetInformation():GetValue(errorSource):HasKey("p")
                                number pval = vResult:GetInformation():GetValue(errorSource):GetValue("p")
                                result:SetInformation(source,"sphericity p", pval)
            
                                number dfn = result:GetInformation():GetValue(source):GetValue("df")
                                number dfd = result:GetInformation():GetValue(source):GetValue("error df")
            
                                number ggcorrection = vResult:GetInformation():GetValue(errorSource):GetValue("gg")
                                fDistribution:Setup(ggcorrection*dfn, ggcorrection*dfd)
                                number ggp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                                result:SetInformation(source,"gg", ggcorrection)
                                result:SetInformation(source,"gg p", ggp)
            
                                number hfcorrection = vResult:GetInformation():GetValue(errorSource):GetValue("hf")
                                fDistribution:Setup(hfcorrection*dfn, hfcorrection*dfd)
                                number hfp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                                result:SetInformation(source,"hf", hfcorrection)
                                result:SetInformation(source,"hf p", hfp)
                            end
    
                            if factorial
                                result:SetEffectSize(source, "partial-eta-squared", partial_eta_squared)
                            else
                                result:SetEffectSize(source, "eta-squared", eta_squared)
                            end               
                        end
                    end
                    i = i + 1
                end
                result:SetFormalTestName("Mixed-Design Analysis of Variance")
                result:Repeated(true)
                result:EqualVariances(true)
                result:NormalDistribution(true)
                result:SetSignificanceLevel(GetSignificanceLevel())
                result:SetFormat(GetStatisticalFormatting())
                result:SetFactors(factorHeaders)
                result:SetColumns(columnHeaders)
                result:SetSources(sources)
                result:SetGroupsFrame(betweenResult:GetGroupsFrame())
                result:SetVarianceResult(vResult)
                if userRequestedPairwise or significantBetween or significantWithin
                    // Pairwise tests are only necessary if the anova is significant
                    CompareMeansPairwise compare
                    compare:SetSignificanceLevel(GetSignificanceLevel())
                    compare:SetStatisticalFormatting(GetStatisticalFormatting())
                    compare:UseLenientCorrection(useLenientCorrection)
                    compare:UseStrictCorrection(useStrictCorrection)
                    compare:SetExperimentalDesign(design)
                    compare:Calculate(result)
                    result:SetPairwiseResults(compare:GetResults())
                end
                results:Add(result)
            end
        else
            CompareSeveralMeans(frame)
        end

        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Analysis of variance (ANOVA) for 3 or more independent groups.

        Null hypothesis: The means are equal across all samples.
        Alternative hypothesis: At least one mean is not equal to the others.

        Assumptions:
            1. Two or more samples:
                If two samples: Best to use a Two-Sample T-Test     > CompareMeans:CompareTwoMeans
              
            2. Samples are independent:
                If not independent: Use a Repeated Measures Anova   > CompareMeans:CompareSeveralRelatedMeans

            3. Samples are normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not normal: Use a Kruskal-Wallis Test            > CompareMeans:CompareSeveralRankedMeans

            4. Samples have equal variances:
                To test this: Use a Levene's Test                   > CompareVariances:CompareIndependentVariances
                If not equal: Use Welch's Anova                     > CompareMeans:AssumeEqualVariances(false)

        Post-Hoc Analysis:
            If this test is significant it may help to run a post hoc follow-up test
            This can be done using a CompareMeansPairwise test and passing the result from this test as the parameter
                Use a Tukey's Multiple Comparison Test              > CompareMeansPairwise > UseLenientCorrection(true)

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumns(0)
        frame:AddSelectedColumns(1)
        frame:AddSelectedColumns(2)
        CompareMeans compare = frame:CompareMeans()
        output compare:GetSummary()
    */
    action CompareSeveralMeans(DataFrame frame)
        ranked = false
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end

        if groups:GetSize() < 2
            alert("CompareSeveralMeans must have at least two samples.")
        end

        boolean equalVariances = assumeEqualVariances or defaultVarianceAssumption

        if not equalVariances and not repeated
            if factorial
                alert("A factorial CompareMeans test with unequal variances is not supported yet.")
            end
            if multivariate
                alert("A multivariate CompareMeans test with unequal variances is not supported yet.")
            end
            // One-Way Welch's ANOVA
            // Assumption of equal variances has been violated
            // For more information: https://www.rips-irsp.com/articles/10.5334/irsp.198/

            CompareMeansResult result
            DataFrame groupFrame

            Matrix groupMeans 
            groupMeans:Fill(1, groups:GetSize(), 0)
            Matrix groupSizes
            groupSizes:Fill(1, groups:GetSize(), 0)
            Matrix groupWeights
            groupWeights:Fill(1, groups:GetSize(), 0)

            // Calculate Means, Weights and Sizes for each group
            Array<text> groupsArray = groups:CopyToKeyArray()
            i = 0
            repeat while i < groupsArray:GetSize()
                text groupText = groupsArray:Get(i)
                DataFrameColumn column = groups:GetValue(groupText):GetColumn(0)
                column:SetHeader(groupText)
                groupFrame:AddColumn(column)

                Matrix group = groups:GetValue(groupText):ConvertToMatrix()
                    
                integer size = group:GetRows()
                groupMeans:SetColumn(i, group:GetMean()) 
                groupSizes:SetColumn(i, size)
                groupWeights:SetColumn(i, size / group:GetVariance())

                result:SetInformation(groupText, "Mean", group:GetMean()) 
                result:SetInformation(groupText, "Size", size)
                if size < 2
                    alert("Samples must have 2 or more observations. Group "+groupText+" has only "+size+" observation. Not enough data for a comparison to be calculated.")
                end
                i = i + 1
            end

            // Calculate welch's F
            // For more information: https://www.discoveringstatistics.com/docs/welchf.pdf
            number totalSumOfWeights = groupWeights:GetTotal()
            number totalWeightedMean = groupWeights:MultiplyElements(groupMeans):GetTotal()
            totalWeightedMean = totalWeightedMean / totalSumOfWeights  

            number sumOfWeightedSquares = 0
            number sumForLambda = 0
            i = 0
            repeat while i < groupWeights:GetColumns()
                number value1 = (1.0 - (groupWeights:Get(0,i) / totalSumOfWeights))
                sumForLambda = sumForLambda + (value1 * value1 / (groupSizes:Get(0,i) - 1.0))

                number value2 = groupMeans:Get(0,i) - totalWeightedMean
                sumOfWeightedSquares = sumOfWeightedSquares + groupWeights:Get(0,i) * (value2 * value2)
                i = i + 1
            end
            number lambda = (3.0 * sumForLambda) / (groups:GetSize() * groups:GetSize() - 1.0)
            number numeratorDegreesOfFreedom = groups:GetSize() - 1.0
            number denominatorDegreesOfFreedom = 1.0 / lambda
            number numerator = sumOfWeightedSquares / (groups:GetSize() - 1.0)
            number denominator = 1.0 + (2.0 * (groups:GetSize() - 2.0) * (lambda / 3.0))

            number f = numerator / denominator
            fDistribution:Setup(numeratorDegreesOfFreedom, denominatorDegreesOfFreedom)
            number p = 1.0 - fDistribution:CumulativeDistribution(f)
            number omega_squared = (numeratorDegreesOfFreedom * (f - 1.0)) / (numeratorDegreesOfFreedom * (f - 1.0) + groupSizes:GetTotal())

            Array<text> sources
            text source = ""
            source = "Between Groups"
            if numberOfFactors = 1
                source = factorHeaders:Get(0)
            end
            sources:Add(source)
            result:SetTestStatistic(source, "Welch's F", f)
            result:SetEffectSize(source, "omega-squared", omega_squared)
            result:SetDegreesOfFreedom(source, "numerator", numeratorDegreesOfFreedom)
            result:SetDegreesOfFreedom(source, "denominator", denominatorDegreesOfFreedom)
            result:SetProbabilityValue(source, source, p)
            result:NormalDistribution(true)
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            result:SetFormalTestName("Welch's One-Way Analysis of Variance")
            result:SetGroupsFrame(groupFrame)
            result:SetFactors(factorHeaders)
            result:SetColumns(columnHeaders)
            result:SetSources(sources)
            result:SetInformation(source, "F", f)
            result:SetInformation(source, "p", p)
            result:SetInformation(source, "df", numeratorDegreesOfFreedom)
            result:SetInformation(source, "error df", denominatorDegreesOfFreedom)
            result:SetInformation(source, "omega-squared", omega_squared)
            
            if userRequestedPairwise or p <= GetSignificanceLevel()
                // Pairwise tests are only necessary if the anova is significant
                CompareMeansPairwise compare
                compare:SetSignificanceLevel(GetSignificanceLevel())
                compare:SetStatisticalFormatting(GetStatisticalFormatting())
                compare:UseLenientCorrection(useLenientCorrection)
                compare:UseStrictCorrection(useStrictCorrection)
                compare:SetExperimentalDesign(design)
                compare:Calculate(result)
                result:SetPairwiseResults(compare:GetResults())
            end
            results:Add(result)
        else
            designMatrix = GetInitialMatrix()
            Matrix responseMatrix
    
            if designFrame:GetSelectedFactorSize() > 0 
                integer current = AddFactorsToDesignMatrix(designFrame, designMatrix)
                integer start = 1
                integer next = start + 1
                integer stop = current - 1
                if designFrame:GetSelectedFactorSize() > 1
                    AddInteractionsToDesignMatrix(designMatrix, 0, start, next, stop, current)
                end
    
                DataFrame dependent
                i = 0
                repeat while i < numberOfColumns
                    DataFrameColumn column = designFrame:GetColumn(designFrame:GetSelection():GetColumn(i))
                    dependent:AddColumn(column)
                    i = i + 1
                end
                responseMatrix = dependent:ConvertToMatrix()
            else
                designMatrix:SetSize(designMatrix:GetRows(), numberOfColumns)
                designMatrix:SetColumn(0, 1)
                responseMatrix:SetSize(designMatrix:GetRows(), 1)
    
                TextColumn levels
                integer rowIndex = 0
                i = 0
                repeat while i < numberOfColumns
                    DataFrameColumn column = designFrame:GetColumn(designFrame:GetSelection():GetColumn(i))
                    j = 0
                    repeat while j < column:GetSize()
                        number value = column:GetAsNumber(j)  
                        if i <  numberOfColumns - 1 // we need size-1 design matrix columns
                            designMatrix:Set(rowIndex, i+1, 1)
                        end
                        responseMatrix:Set(rowIndex, 0, value)   
                        rowIndex = rowIndex + 1           
                        j = j + 1
                    end
                    levels:Add(column:GetHeader())
                    factorsAssociatedWithColumn:Add(i+1, GetInitialEncoding(numberOfColumns))
                    factorsAssociatedWithColumn:GetValue(i+1):Set(0, 0, 1)
                    i = i + 1
                end
                factorIndex:Add(0, "between")
                factorLevels:Add(levels)
                factorsAssociatedWithColumn:Add(0, GetInitialEncoding(numberOfColumns))
            end

            CompareMeansResult result
            if multivariate
                result:SetGroupsTable(groups)
            else
                DataFrame groupFrame
                Array<text> groupsArray = groups:CopyToKeyArray()
                i = 0
                repeat while i < groupsArray:GetSize()
                    text groupText = groupsArray:Get(i)
                    DataFrameColumn column = groups:GetValue(groupText):GetColumn(0)
                    if column:GetSize() < 2 and not repeated
                        alert("Samples must have 2 or more observations. Group "+groupText+" has only "+column:GetSize()+" observation. Not enough data for a comparison to be calculated.")
                    end
                    column:SetHeader(groupText)
                    groupFrame:AddColumn(column)
                    i = i + 1
                end
                result:SetGroupsFrame(groupFrame)
            end

            HashTable<text, number> ssFactors   // univariate
            HashTable<text, Matrix> sscpFactors // multivariate
            HashTable<text, number> dfFactors 

            Matrix sscpResiduals
            number ssResiduals = 0
            number dfResiduals = 0
      
            // Sum Of Squares Residuals
            if not repeated
                dfResiduals = totalObservations - 1 // Total degrees of freedom to start.
                if multivariate
                    sscpResiduals = ComputeSumOfSquaresCrossProductMatrix(designMatrix, responseMatrix)
                else
                    ssResiduals = ComputeSumOfSquares(designMatrix, responseMatrix)
                end
            end

            // Sum Of Squares For Each Factor And Interaction (This type II ss calc is not currently that efficient)
            i = 1 // Skip Intercept
            repeat while i <= factorsAssociatedWithColumn:GetSize()
                Matrix factorEncoding = factorsAssociatedWithColumn:GetValue(i)
            
                if factorEncoding not= undefined
                    text factor = GetTextFromEncoding(factorEncoding)
                    if not ssFactors:HasKey(factor)
                        Matrix without = RemoveAssociated(factorEncoding, designMatrix)     // Columns of design matrix wihout any association at all to this factor/interaction
                        Matrix with = AddMatching(factorEncoding, designMatrix, without)    // Columns associated perfectly with this factor added back (no partial associations)              

                        if multivariate
                            Matrix withoutSSCP = ComputeSumOfSquaresCrossProductMatrix(without, responseMatrix)
                            Matrix withSSCP = ComputeSumOfSquaresCrossProductMatrix(with, responseMatrix)
    
                            Matrix sscp = withoutSSCP:SubtractElements(withSSCP)
                            sscpFactors:Add(factor, sscp)
                        else
                            number withoutSS = ComputeSumOfSquares(without, responseMatrix)
                            number withSS = ComputeSumOfSquares(with, responseMatrix)
    
                            number ss = withoutSS - withSS
                            ssFactors:Add(factor, ss)
                        end
                    end
    
                    if not dfFactors:HasKey(factor)
                        number df = GetDegreesOfFreedomFromEncoding(factorEncoding)
                        dfFactors:Add(factor, df)
                        if not repeated
                            dfResiduals = dfResiduals - df
                        end
                    end
                end
                i = i + 1
            end

            boolean significant = false
            Array<text> sources
            Array<text> dfFactorArray = dfFactors:CopyToKeyArray()
            number ssSubjects = 0
            number dfSubjects = 0
            number ssTotal = 0  
            number dfTotal = 0
            number ssTotalError = 0  
            number dfTotalError = 0  
            if ssResiduals not= ssResiduals:GetNotANumberValue()    
                ssTotal = ssResiduals 
                dfTotal = dfResiduals
                ssTotalError = ssResiduals 
                dfTotalError = dfResiduals
            end
            number ssMeasured = 0
            number measuredVariation = 0
            if not multivariate
                i = 0
                repeat while i < dfFactorArray:GetSize()
                    text factor = dfFactorArray:Get(i)
                    number ssFactor = ssFactors:GetValue(factor)
                    number dfFactor = dfFactors:GetValue(factor)
                    if repeated
                        text factorError = design:GetSubjectIdentifier()+":"+factor
                        if dfFactors:HasKey(factorError)
                            number ssError = ssFactors:GetValue(factorError)
                            number dfError = dfFactors:GetValue(factorError)
    
                            ssMeasured = ssMeasured + ssError
                            measuredVariation = measuredVariation + (ssFactor + dfFactor * (ssError / dfError))

                            ssTotalError = ssTotalError + ssError
                            dfTotalError = dfTotalError + dfError
                        end
                        if factor = design:GetSubjectIdentifier()
                            ssSubjects = ssFactors:GetValue(factor)
                            dfSubjects = dfFactors:GetValue(factor)

                            ssTotalError = ssTotalError + ssSubjects
                            dfTotalError = dfTotalError + dfSubjects
                        end
                    end
                    ssTotal = ssTotal + ssFactors:GetValue(factor)
                    dfTotal = dfTotal + dfFactors:GetValue(factor)
                    i = i + 1
                end
            end

            number numberOfObservations = design:GetNumberOfObservations()
            i = 0
            repeat while i < dfFactorArray:GetSize()
                text factor = dfFactorArray:Get(i)
                if multivariate
                    Matrix sscpFactor = sscpFactors:GetValue(factor)
                    number dfFactor = dfFactors:GetValue(factor)

                    text source = "Between Groups"
                    if repeated 
                        source = "Between Measures"
                    end
                    if numberOfFactors > 0
                        source = factor
                    end
                    sources:Add(source)
                    result:SetInformation(source, "sscp", sscpFactor)
                    result:SetDegreesOfFreedom(source, source, dfFactor)

                    boolean skipFactor = false
                    if repeated
                        text factorError = design:GetSubjectIdentifier()+":"+factor
                        if dfFactors:HasKey(factorError)
                            sscpResiduals = sscpFactors:GetValue(factorError)
                            dfResiduals = dfFactors:GetValue(factorError)
                        else
                            skipFactor = true
                        end
                    end

                    if not skipFactor // This will skip any error terms
                        // See: https://ebook.upgrisba.ac.id/ebook/komputer-informasi-referensi-umum/6th-edition-using-multivariate-statistics-pearson/download  
                      
                        // Wilk’s Lambda Test
                        number wilksLambda = sscpResiduals:GetDeterminant() / sscpResiduals:AddElements(sscpFactor):GetDeterminant()
                        number numberOfVariables = numberOfColumns          // number of dependent variables
                        number df1 = numberOfVariables*dfFactor
                        number df2 = (dfResiduals - numberOfVariables + 1)*dfFactor
                        number s = math:MinimumOf(numberOfVariables, dfFactor)
                        number t = 1.0
                        number numerator = (numberOfVariables * numberOfVariables * dfFactor * dfFactor - 4.0)
                        number denominator = (numberOfVariables * numberOfVariables + dfFactor * dfFactor - 5.0)
                        if numerator not= 0 and denominator not= 0
                            t = math:SquareRoot(numerator / denominator)
                        end
                        number f = ((1.0 - math:RaiseToPower(wilksLambda, 1.0/t)) / math:RaiseToPower(wilksLambda, 1.0/t)) * (df2 / df1)
                        fDistribution:Setup(df1, df2)
                        number pvalue = 1.0 - fDistribution:CumulativeDistribution(f)
                        text statSource = source+"Wilks Lambda"
                        result:SetTestStatistic(source, "Wilks Lambda", wilksLambda)
                        result:SetTestStatistic(statSource, "F", f)
                        result:SetDegreesOfFreedom(statSource, "numerator", df1)
                        result:SetDegreesOfFreedom(statSource, "denominator", df2)
                        result:SetProbabilityValue(statSource, statSource, pvalue)

                        // multivariate eta-squared estimate: http://friendly.github.io/heplots/reference/etasq.html
                        // adjusted multivariate omega-squared estimate: https://core.ecu.edu/wuenschk/MV/MANOVA/MANOVA_Omega-Squared.docx
                        number partial_eta_squared = 1.0 - math:RaiseToPower(wilksLambda, 1.0/ s)
                        number partial_omega_squared = 1.0 - ((numberOfObservations - 1) / (numberOfObservations - math:MaximumOf(numberOfVariables, dfFactor) - 1)) * (1 - partial_eta_squared) 

                        result:SetEffectSize(statSource, "partial-eta-squared", partial_eta_squared)
                        result:SetInformation(source, "wilks", wilksLambda)
                        result:SetInformation(source, "wilks f", f)
                        result:SetInformation(source, "wilks dfn", df1)
                        result:SetInformation(source, "wilks dfd", df2)
                        result:SetInformation(source, "wilks p", pvalue)
                        result:SetInformation(source, "wilks pes", partial_eta_squared)
                        result:SetInformation(source, "wilks pos", partial_omega_squared)

                        // Hotelling-Lawley Trace Test
                        number hotellingTrace = sscpFactor:Multiply(sscpResiduals:Inverse()):GetTrace()
                        number m = (math:AbsoluteValue(numberOfVariables - dfFactor) - 1.0) / 2.0
                        number n = (dfResiduals - numberOfVariables - 1.0) / 2.0
                        df1 = s * math:MaximumOf(numberOfVariables,dfFactor)
                        df2 = 2.0 * (s * n + 1.0) 
                        f = (hotellingTrace / s) * (df2 / df1)
                        fDistribution:Setup(df1, df2)
                        pvalue = 1.0 - fDistribution:CumulativeDistribution(f)
                        statSource = source+"Hotelling Trace"
                        result:SetTestStatistic(source, "Hotelling Trace", hotellingTrace)
                        result:SetTestStatistic(statSource, "F", f)
                        result:SetDegreesOfFreedom(statSource, "numerator", df1)
                        result:SetDegreesOfFreedom(statSource, "denominator", df2)
                        result:SetProbabilityValue(statSource, statSource, pvalue)

                        // multivariate eta-squared estimate: http://friendly.github.io/heplots/reference/etasq.html
                        // adjusted multivariate omega-squared estimate: https://core.ecu.edu/wuenschk/MV/MANOVA/MANOVA_Omega-Squared.docx
                        partial_eta_squared = hotellingTrace / (hotellingTrace + s)
                        partial_omega_squared = 1.0 - ((numberOfObservations - 1) / (numberOfObservations - math:MaximumOf(numberOfVariables, dfFactor) - 1)) * (1 - partial_eta_squared) 
                        result:SetEffectSize(statSource, "partial-eta-squared", partial_eta_squared)
                        result:SetInformation(source, "hotelling", hotellingTrace)
                        result:SetInformation(source, "hotelling f", f)
                        result:SetInformation(source, "hotelling dfn", df1)
                        result:SetInformation(source, "hotelling dfd", df2)
                        result:SetInformation(source, "hotelling p", pvalue)
                        result:SetInformation(source, "hotelling pes", partial_eta_squared)
                        result:SetInformation(source, "hotelling pos", partial_omega_squared)

                        // Pillai-Barlett Trace Test 
                        number pillaiTrace = sscpFactor:Multiply(sscpFactor:AddElements(sscpResiduals):Inverse()):GetTrace()
                        df1 = s * (2.0 * m + s + 1.0)
                        df2 = s * (2.0 * n + s + 1.0) 
                        f = (pillaiTrace / (s - pillaiTrace)) * (df2 / df1)
                        fDistribution:Setup(df1, df2)
                        pvalue = 1.0 - fDistribution:CumulativeDistribution(f)
                        statSource = source+"Pillai Trace"
                        result:SetTestStatistic(source, "Pillai Trace", pillaiTrace)
                        result:SetTestStatistic(statSource, "F", f)
                        result:SetDegreesOfFreedom(statSource, "numerator", df1)
                        result:SetDegreesOfFreedom(statSource, "denominator", df2)
                        result:SetProbabilityValue(statSource, statSource, pvalue)

                        // multivariate eta-squared estimate: http://friendly.github.io/heplots/reference/etasq.html
                        // adjusted multivariate omega-squared estimate: https://core.ecu.edu/wuenschk/MV/MANOVA/MANOVA_Omega-Squared.docx
                        partial_eta_squared = pillaiTrace / s
                        partial_omega_squared = 1.0 - ((numberOfObservations - 1) / (numberOfObservations - math:MaximumOf(numberOfVariables, dfFactor) - 1)) * (1 - partial_eta_squared) 

                        result:SetEffectSize(statSource, "partial-eta-squared", partial_eta_squared)
                        result:SetInformation(source, "pillai", pillaiTrace)
                        result:SetInformation(source, "pillai f", f)
                        result:SetInformation(source, "pillai dfn", df1)
                        result:SetInformation(source, "pillai dfd", df2)
                        result:SetInformation(source, "pillai p", pvalue)
                        result:SetInformation(source, "pillai pes", partial_eta_squared)
                        result:SetInformation(source, "pillai pos", partial_omega_squared)

                        result:SetInformation(source, "df", dfFactor)
                        result:SetInformation(source, "error df", dfResiduals)

                        significant = pvalue <= GetSignificanceLevel()
                    end
                else
                    number ssFactor = ssFactors:GetValue(factor)
                    number dfFactor = dfFactors:GetValue(factor)
    
                    boolean skipFactor = false
                    if repeated
                        text factorError = design:GetSubjectIdentifier()+":"+factor
                        if dfFactors:HasKey(factorError)
                            ssResiduals = ssFactors:GetValue(factorError)
                            dfResiduals = dfFactors:GetValue(factorError)
                        else
                            skipFactor = true
                        end
                        if factor = design:GetSubjectIdentifier()
                            text source = design:GetSubjectIdentifier()
                            sources:Add(source)
                            result:SetDegreesOfFreedom(source, source, dfFactor)
                            result:SetInformation(source, "ss", ssFactor)
                            result:SetInformation(source, "df", dfFactor)
                            result:SetInformation(source, "meanss", ssFactor / dfFactor)
                        end
                    end
        
                    if not skipFactor // This will skip any error terms     
                        number meanSSFactor = ssFactor / dfFactor
                        number meanSSResiduals = ssResiduals / dfResiduals
                        number factorVariation = (ssFactor - dfFactor * meanSSResiduals)
                        fDistribution:Setup(dfFactor, dfResiduals)
                        number f = meanSSFactor / meanSSResiduals
                        number p = 1.0 - fDistribution:CumulativeDistribution(f)
                        
                        // The generalization calculations assume all factors to be manipulated by default
                        HashTable<text, text> measuredFactors
                        number d = 1
                        if measuredFactors:HasKey(factor)
                            d = 0
                        end

                        number eta_squared = 0 
                        number partial_eta_squared = 0
                        number generalized_eta_squared = 0 
                        number omega_squared = 0 
                        number partial_omega_squared = 0
                        number generalized_omega_squared = 0 
                        if repeated
                            if factor = design:GetSubjectIdentifier()
                                d = 0
                            end
                            // See page 379: https://link.springer.com/article/10.3758/BF03192707
                            eta_squared = ssFactor / ssTotal
                            // See page 380: https://link.springer.com/article/10.3758/BF03192707
                            partial_eta_squared = ssFactor / (ssFactor + ssResiduals)
                            // See page 437 & 439: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            generalized_eta_squared = ssFactor / (d * ssFactor /* + measured is always zero in rm */ + ssTotalError)

                            // See page 1: https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
                            omega_squared = factorVariation / (ssTotal + (ssSubjects / dfSubjects))
                            // See: https://www.aggieerin.com/shiny-server/tests/omegaprmss.html
                            // partial_omega_squared = factorVariation / (ssFactor + (numberOfObservations - dfFactor) * (ssResiduals / dfResiduals))
                            // See page 1: https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
                            partial_omega_squared = factorVariation / (ssFactor + ssResiduals + ssSubjects + (ssSubjects / dfSubjects))
                            // See page 441 & 443: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            generalized_omega_squared = factorVariation / (d * factorVariation /* + measured is always zero in rm */ + numberOfObservations * (ssTotalError / dfTotalError))
                        else
                            // See page 435: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            eta_squared = ssFactor / ssTotal
                            // See page 435: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            partial_eta_squared = ssFactor / (ssFactor + ssResiduals)
                            // See page 437: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            generalized_eta_squared = ssFactor / (d * ssFactor + ssMeasured + ssResiduals)

                            // See page 1: https://www.jasonfinley.com/tools/OmegaSquaredQuickRef_JRF_3-31-13.pdf
                            omega_squared = factorVariation / (ssTotal + meanSSResiduals)
                            // See page 435: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            partial_omega_squared = factorVariation / (ssFactor + (numberOfObservations - dfFactor) * meanSSResiduals)
                            // See page 441: http://coshima.davidrjfikis.com/EPRS8540/uploadf07/olejnik_PsychMeth2003.pdf
                            generalized_omega_squared = factorVariation / (d * factorVariation + measuredVariation + numberOfObservations * meanSSResiduals)
                        end
                        
                        text source = "Groups"
                        if repeated 
                            source = "Measures"
                        end
                        if numberOfFactors > 0
                            source = factor
                        end
                        sources:Add(source)
                        result:SetTestStatistic(source, "F", f)
                        result:SetDegreesOfFreedom(source, "F", dfFactor)
                        result:SetProbabilityValue(source, "F", p)
                        result:SetInformation(source, "F", f)
                        result:SetInformation(source, "p", p)
                        result:SetInformation(source, "ss", ssFactor)
                        result:SetInformation(source, "df", dfFactor)
                        result:SetInformation(source, "meanss", meanSSFactor)
                        result:SetInformation(source, "error ss", ssResiduals)
                        result:SetInformation(source, "error df", dfResiduals)

                        result:SetInformation(source, "eta-squared", eta_squared)
                        result:SetInformation(source, "partial-eta-squared", partial_eta_squared)
                        result:SetInformation(source, "generalized-eta-squared", generalized_eta_squared)
                        result:SetInformation(source, "omega-squared", omega_squared)
                        result:SetInformation(source, "partial-omega-squared", partial_omega_squared)
                        result:SetInformation(source, "generalized-omega-squared", generalized_omega_squared)
                        
                        if factorial
                            result:SetEffectSize(source, "partial-eta-squared", partial_eta_squared)
                        else
                            result:SetEffectSize(source, "eta-squared", eta_squared)
                        end
    
                        significant = p <= GetSignificanceLevel()
                    end
                end
                i = i + 1
            end

            if not repeated
                source = "Residual Error" 
                sources:Add(source)
                result:SetDegreesOfFreedom(source, source, dfResiduals)
                if multivariate
                    result:SetInformation(source,"ss", sscpResiduals)
                    result:SetInformation(source,"df", dfResiduals)
                else
                    result:SetInformation(source,"ss", ssResiduals)
                    result:SetInformation(source,"df", dfResiduals)
                    result:SetInformation(source,"meanss", ssResiduals / dfResiduals)
                end               
            end

            result:Repeated(repeated)
            result:EqualVariances(true)
            result:NormalDistribution(true)
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            result:SetFactors(factorHeaders)
            result:SetColumns(columnHeaders)
            result:SetSources(sources)
            if repeated
                if multivariate
                    if factorial
                        result:SetFormalTestName("Multivariate Repeated Measures Analysis of Variance")
                    else
                        result:SetFormalTestName("One-Way Multivariate Repeated Measures Analysis of Variance")
                    end
                else
                    if factorial
                        result:SetFormalTestName("Repeated Measures Analysis of Variance")
                    else
                        result:SetFormalTestName("One-Way Repeated Measures Analysis of Variance")
                    end
                end
            else
                if multivariate
                    if factorial
                        result:SetFormalTestName("Multivariate Analysis of Variance")
                    else
                        result:SetFormalTestName("One-Way Multivariate Analysis of Variance")
                    end
                else
                    if factorial
                        result:SetFormalTestName("Analysis of Variance")
                    else
                        result:SetFormalTestName("One-Way Analysis of Variance")
                    end
                end
            end

            if testDistributionAssumption
                if multivariate
                    alert("Testing for normal distribution on multiple dependent variables is not supported yet")
                end
                // Check normality using a Shapiro-Wilk's CompareDistributions Test
                CompareDistributions compare
                compare:SetSignificanceLevel(GetSignificanceLevel())
                compare:SetStatisticalFormatting(GetStatisticalFormatting())
                result:GetGroupsFrame():SelectAllColumns()
                compare:CompareDistributionToNormal(result:GetGroupsFrame())
                result:SetDistributionResults(compare:GetResults())
            end
            if testVarianceAssumption or (repeated and significant)
                if repeated 
                    if testVarianceAssumption and multivariate
                        alert("A multivariate repeated measures CompareVariances test is not supported yet.")
                    end
                    if not multivariate
                        // Check for sphericity using a Mauchly's CompareVariances test 
                        // This test is only necessary if the rm anova is significant with standard f
                        ExperimentalDesign withinDesign
                        withinDesign:AddSubjectIdentifier(design:GetSubjectIdentifier())
                        Array<text> within = design:GetWithinSubjectsFactors()
                        i = 0
                        repeat while i < within:GetSize()
                            withinDesign:AddWithinSubjectsFactor(within:Get(i))
                            i = i + 1
                        end 
                        Array<text> dv = design:GetDependentVariables()
                        i = 0
                        repeat while i < dv:GetSize()
                            withinDesign:AddDependentVariable(dv:Get(i))
                            i = i + 1
                        end
                        withinDesign:Transform(designFrame)

                        CompareVariances mauchly
                        mauchly:RepeatedMeasures(true)
                        mauchly:SetSignificanceLevel(GetSignificanceLevel())
                        mauchly:SetStatisticalFormatting(GetStatisticalFormatting())
                        mauchly:SetExperimentalDesign(withinDesign)
                        mauchly:Calculate(frame)
                        CompareVariancesResult mauchlyResult = mauchly:GetResult()
                        result:SetVarianceResult(mauchlyResult)

                        i = 0
                        repeat while i < sources:GetSize()
                            text source = sources:Get(i)
                            if mauchlyResult:GetInformation():HasKey(source) and mauchlyResult:GetInformation():GetValue(source):HasKey("p")
                                number p = mauchlyResult:GetInformation():GetValue(source):GetValue("p")
                                result:SetInformation(source,"sphericity p", p)
    
                                number dfn = result:GetInformation():GetValue(source):GetValue("df")
                                number dfd = result:GetInformation():GetValue(source):GetValue("error df")
    
                                number ggcorrection = mauchlyResult:GetInformation():GetValue(source):GetValue("gg")
                                fDistribution:Setup(ggcorrection*dfn, ggcorrection*dfd)
                                number ggp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                                result:SetInformation(source,"gg", ggcorrection)
                                result:SetInformation(source,"gg p", ggp)
    
                                number hfcorrection = mauchlyResult:GetInformation():GetValue(source):GetValue("hf")
                                fDistribution:Setup(hfcorrection*dfn, hfcorrection*dfd)
                                number hfp = 1.0 - fDistribution:CumulativeDistribution(result:GetInformation():GetValue(source):GetValue("F"))
                                result:SetInformation(source,"hf", hfcorrection)
                                result:SetInformation(source,"hf p", hfp)
                            end
                            i = i + 1
                        end
                    end
                elseif testVarianceAssumption
                    if multivariate
                        // Check for homogeneity using a Box's CompareCovarianceMatrices test
                        CompareVariances compare
                        compare:SetSignificanceLevel(GetSignificanceLevel())
                        compare:SetStatisticalFormatting(GetStatisticalFormatting())
                        compare:Calculate(designFrame) // Keep the same selection as this test
                        result:SetVarianceResult(compare:GetResult())
                        if compare:GetResult():IsSignificant()
                            result:UsePillaiStatistic(true) // Use pillai default if Box's fails
                        end
                    else
                        // Check for homogeneity using a Levene's CompareVariances test
                        CompareVariances compare
                        compare:SetSignificanceLevel(GetSignificanceLevel())
                        compare:SetStatisticalFormatting(GetStatisticalFormatting())
                        result:GetGroupsFrame():SelectAllColumns()
                        compare:Calculate(result:GetGroupsFrame())
                        result:SetVarianceResult(compare:GetResult())
                    end
                end
            end
            if userRequestedPairwise or significant
                if userRequestedPairwise and multivariate
                    alert("Pairwise post hoc testing for multivariate designs is not supported yet")
                end
                if not multivariate
                    // Pairwise tests are only necessary if the anova is significant
                    CompareMeansPairwise compare
                    compare:SetSignificanceLevel(GetSignificanceLevel())
                    compare:SetStatisticalFormatting(GetStatisticalFormatting())
                    compare:UseLenientCorrection(useLenientCorrection)
                    compare:UseStrictCorrection(useStrictCorrection)
                    compare:SetExperimentalDesign(design)
                    compare:Calculate(result)
                    result:SetPairwiseResults(compare:GetResults())
                end
            end
            results:Add(result)
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /*
        Wilcoxon Signed-Ranks Test for 1 group against a given median (default is 0)

        Null hypothesis: The median is equal to a proposed median.  
        Alternative hypothesis: The median is not equal to a proposed median.

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumn(0)
    
        CompareMeans compare = frame:CompareToRankedMean(10)
        output compare:GetSummary()
    */
    action CompareToRankedMean(DataFrame frame)
        ranked = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 1
            alert("CompareToRankedMean must have at least one sample.")
        end

        if multivariate
            alert("A non-parametric multivariate one-sample CompareMeans test is not supported yet.")
        else
            Array<text> groupsArray = groups:CopyToKeyArray()
            integer i = 0
            repeat while i < groupsArray:GetSize()
                text groupText = groupsArray:Get(i)

                DataFrame groupFrame = groups:GetValue(groupText)
                DataFrameColumn column = groupFrame:GetColumn(0)
                column:SetHeader(groupText)
                if column:GetSize() < 2
                    alert("Samples must have 2 or more observations. Not enough data for a comparison to be calculated.")
                end
                groupFrame:SelectAllColumns()

                NumberColumn noZerosDifference
                noZerosDifference:SetHeader("noZerosDifference")
                NumberColumn absoluteDifference
                absoluteDifference:SetHeader("absoluteDifference")
                boolean zeroRankWarning = false
                i = 0
                repeat while i < column:GetSize()
                    number value = column:GetAsNumber(i)
                    if value not= 0 // Drop any zero difference from test
                        if value < 0
                            absoluteDifference:Add(math:AbsoluteValue(value))
                        else
                            absoluteDifference:Add(value)
                        end
                        noZerosDifference:Add(value)
                    else
                        zeroRankWarning = true
                    end
                    i = i + 1
                end

                // Sort the data for the difference into ascending order by absolute difference.
                DataFrame sorted
                sorted:AddColumn(noZerosDifference)
                sorted:AddColumn(absoluteDifference)
                sorted:Sort("absoluteDifference")
                
                // Assign ranks to the sorted data points. Give tied values the average rank.
                ConvertColumnsToRanksTransform transform
                transform:AddColumn(1)
                DataFrame ranked = sorted:Transform(transform)

                // Reapply signs to ranks and add to postive or negative sums
                HashTable<text, number> sums
                sums:Add("positive", 0)
                sums:Add("negative", 0)
                DataFrameColumn values = sorted:GetColumn(0)
                DataFrameColumn ranksSigned = ranked:GetColumn(0):Copy()
                i = 0
                repeat while i < ranksSigned:GetSize()
                    number value = values:GetAsNumber(i)
                    number rank = ranksSigned:GetAsNumber(i)
                    if value < userMedian
                        ranksSigned:SetAsNumber(i, -1.0 * rank)
                        sums:Set("negative", sums:GetValue("negative") + rank)
                    else
                        sums:Set("positive", sums:GetValue("positive") + rank)
                    end
                    i = i + 1
                end

                // Calculate the W Statistic, the smaller of the two sums
                number sumPos = sums:GetValue("positive")
                number sumNeg = sums:GetValue("negative")
                number W = math:MinimumOf(sumPos, sumNeg)
        
                // Calculate normal approximation and corrections
                number n = ranksSigned:GetSize()
                number meanW = (n * (n + 1)) / 4.0
                number varW = (n * (n + 1) * (2 * n + 1)) / 24.0
                number tieCorrectionSum = CalculateTieCorrectionSum(ranked:GetColumn(0)) // Do tie correction on unsigned ranks
                if tieCorrectionSum not= 0
                    varW = varW - (tieCorrectionSum / 48.0) // The tie correction
                end
                number sdW = math:SquareRoot(varW)
                number correction = 0
                if correctContinuityError
                    correction = 0.5 // The continuity correction
                end
                number z = (math:AbsoluteValue(W - meanW) - correction) / sdW
        
                // Calculate two-tailed probability value from normal distribution
                number p = 2.0 * (1.0 - zdistribution:CumulativeDistribution(z))
        
                // Calculate effect size
                number r = z / math:SquareRoot(n)
    
                // Save the result
                CompareMeansResult result
                result:Ranked(true)
                result:SetSignificanceLevel(GetSignificanceLevel())
                result:SetFormat(GetStatisticalFormatting())
                result:SetTestStatistic(groupText,"Z", z)
                result:SetEffectSize(groupText,"Rosenthal's r",r)
                result:SetProbabilityValue(groupText,"Z", p)
                result:SetInformation(groupText,"median", groupFrame:Median())
                result:SetInformation(groupText,"variance", groupFrame:Variance())
                result:SetInformation("proposed","median", userMedian)
                result:SetFormalTestName("Wilcoxon Signed-Rank Test")
                result:SetGroupsFrame(groupFrame)
                result:SetFactors(factorHeaders)
                result:SetColumns(columnHeaders)
                results:Add(result)
                i = i + 1
            end
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Wilcoxon Signed-Ranks Test for 2 dependent (paired) groups.
        This can also be used on 1 group.

        Null hypothesis: The difference median is equal to a proposed median.  
        Alternative hypothesis: The difference median is not equal to a proposed median.

        Assumptions:
            1. One or two samples:
                If more than two samples: Use a Friedman Test       > CompareMeans:CompareSeveralRelatedRankedMeans
              
            2. Samples are dependent:
                If not dependent: Use a Mann-Whitney U-Test         > CompareMeans:CompareTwoRankedMeans

            3. Samples are skewed, or not normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not skewed: Use a Paired Two-Sample T-Test       > CompareMeans:CompareTwoRelatedMeans

            4. Samples follow a similarly-shaped distribution
                To test this: Use a Kolmogorov-Smirnov Test         >

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumnRange(0,1)
    
        CompareMeans compare = CompareTwoRelatedRankedMeans(10)
        output compare:GetSummary()
    */
    action CompareTwoRelatedRankedMeans(DataFrame frame)
        ranked = true
        repeated = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 2
            alert("CompareTwoRelatedRankedMeans must have at least two samples.")
        end
        if multivariate
            alert("A non-parametric multivariate one-sample CompareMeans test is not supported yet.")
        else
            Array<text> groupsArray = groups:CopyToKeyArray()
            integer i = 0
            repeat while i < groupsArray:GetSize()
                integer j = i + 1
                repeat while j < groupsArray:GetSize()
                    text group1Text = groupsArray:Get(i)
                    text group2Text = groupsArray:Get(j)
                    text combo = group1Text+"_"+group2Text

                    DataFrameColumn left = groups:GetValue(group1Text):GetColumn(0)
                    left:SetHeader(group1Text)
                    DataFrameColumn right = groups:GetValue(group2Text):GetColumn(0)
                    right:SetHeader(group2Text)

                    // Paired data should be the same size
                    if left:GetSize() not= right:GetSize()
                        alert("Samples must be the same size for a paired design. " + left:GetHeader() + " is a different size than "+ right:GetHeader() + ".")
                    end
                    if left:GetSize() < 2 or right:GetSize() < 2
                        alert("Samples must have 2 or more observations. Not enough data for a comparison to be calculated.")
                    end

                    DataFrame groupFrame
                    groupFrame:AddColumn(left)
                    groupFrame:AddColumn(right)

                    // Calculate the test statistics
                    Summarize summarizeL
                    left:Calculate(summarizeL)
                    number median1 = summarizeL:GetMedian()
                    number size1 = left:GetSize()

                    Summarize summarizeR
                    right:Calculate(summarizeR)
                    number median2 = summarizeR:GetMedian()
                    number size2 = right:GetSize()

                    // Create difference column/frame
                    NumberColumn numLeft = left:ConvertToNumberColumn()
                    NumberColumn numRight = right:ConvertToNumberColumn()
                    NumberColumn difference = numLeft:Subtract(numRight)
                    difference:SetHeader("difference")
                    DataFrame diffFrame
                    diffFrame:AddColumn(difference)
                    diffFrame:SelectAllColumns()
                    number diffMedian = diffFrame:Median()
                    number diffVar = diffFrame:Variance()

                    // Run a one-sample test on the difference
                    CompareMeans compare1
                    compare1:SetMean(userMedian)
                    compare1:CompareToRankedMean(diffFrame)
                    CompareMeansResult res = compare1:GetResult()
                    text statName = res:GetTestStatisticName()

                    // Save the result
                    CompareMeansResult result
                    result:Ranked(true)
                    result:Repeated(true)
                    result:SetSignificanceLevel(GetSignificanceLevel())
                    result:SetFormat(GetStatisticalFormatting())
                    result:SetTestStatistic(combo, statName, res:GetTestStatistic())
                    result:SetEffectSize(combo, res:GetEffectSizeName(), res:GetEffectSize())
                    result:SetProbabilityValue(combo, statName, res:GetProbabilityValue())
                    result:SetInformation(group1Text,"median", median1)
                    result:SetInformation(group1Text,"size", size1)
                    result:SetInformation(group2Text,"median", median2)
                    result:SetInformation(group2Text,"size", size2)
                    result:SetInformation("difference","median", diffMedian)
                    result:SetInformation("difference","variance", diffVar)
                    result:SetInformation("proposed","median", userMedian)
                    result:SetFormalTestName("Paired Wilcoxon Signed-Rank Test")
                    result:SetGroupsFrame(groupFrame)
                    result:SetFactors(factorHeaders)
                    result:SetColumns(columnHeaders)
                    results:Add(result)
                    j = j + 1
                end
                i = i + 1
            end
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Mann-Whitney U-Test aka Wilcoxon Rank-Sum Test is for 2 independent samples.

        Null hypothesis: The two populations are equal
        Alternative hypothesis: The two populations are not equal

        Assumptions:
            1. Two samples:
                If more than two samples: Use a Kruskal-Wallis Test > CompareMeans:CompareSeveralRankedMeans
              
            2. Samples are independent:
                If not independent: Wilcoxon Signed-Rank Test       > CompareMeans:CompareTwoRelatedRankedMeans

            3. Samples are skewed, or not normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not skewed: Use a Two-Sample T-Test              > CompareMeans:CompareTwoMeans

            4. Samples follow a similarly-shaped distribution
                To test this: Use a Kolmogorov-Smirnov Test         >

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")
        frame:AddSelectedColumnRange(0,1)
    
        CompareMeans compare = frame:CompareRankedMeans()
        output compare:GetSummary()
    */
    action CompareTwoRankedMeans(DataFrame frame)
        ranked = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if multivariate
            alert("A non-parametric multivariate two-sample CompareMeans test is not supported yet.")
        else
            DataFrame groupFrame = design:GetGroupsFrame()
            if groupFrame:GetSize() < 2
                alert("CompareTwoRankedMeans must have two samples.")
            elseif groupFrame:GetSize() > 2
                alert("CompareTwoRankedMeans must have two samples. Use CompareMeansPairwise or CompareSeveralRankedMeans.")
            end

            DataFrameColumn left = groupFrame:GetColumn(0)
            DataFrameColumn right = groupFrame:GetColumn(1)
            text group1Text = left:GetHeader()
            text group2Text = right:GetHeader()
            text combo = group1Text+"_"+group2Text

            if left:GetSize() < 2 
                alert("Samples must have 2 or more observations. "+group1Text+" only has "+left:GetSize()+". Not enough data for a comparison to be calculated.")
            end
            if right:GetSize() < 2
                alert("Samples must have 2 or more observations. "+group2Text+" only has "+right:GetSize()+". Not enough data for a comparison to be calculated.")
            end

            // Rank the data all a whole and get groups
            DataFrame rankedLong = design:GetRankedFrame()
            DataFrame rankedGroupsFrame = rankedLong:CreateNewDataFrameFromFactoredColumns()
            rankedGroupsFrame:SelectAllColumns()
            groupFrame:SelectAllColumns()
            Array<Summarize> groupSummaries = groupFrame:SummarizeSelectedColumns()
            Array<Summarize> rankSummaries = rankedGroupsFrame:SummarizeSelectedColumns()


            number n1 = left:GetSize()
            number n2 = right:GetSize()
            number sum1 = rankSummaries:Get(0):GetSum()
            number sum2 = rankSummaries:Get(1):GetSum()

            // Calculate the W statistic, the smaller of the two u values
            number u1 = n1 * n2 + (n1 * (n1 + 1) / 2.0) - sum1
            number u2 = n1 * n2 + (n2 * (n2 + 1) / 2.0) - sum2
            number U = math:MinimumOf(u1, u2)
            
            // Calculate normal approximation and corrections
            // See: https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation_and_tie_correction
            number N = n1 + n2
            number meanSum = n1 * n2 / 2.0 // The expected mean
            number varSum = n1 * n2 * (N + 1) / 12.0
            number tieCorrectionSum = CalculateTieCorrectionSum(rankedLong:GetColumn(design:GetDependentVariables():Get(0)))
            if tieCorrectionSum not= 0
                varSum = (n1 * n2 / 12.0) * ((N + 1) - (tieCorrectionSum / (N * (N - 1)))) // The tie correction
            end
            number sdSum = math:SquareRoot(varSum)
            number correction = 0
            if correctContinuityError
                if U < meanSum
                    correction = 0.5
                else
                    correction = -0.5 // The continuity correction
                end
            end                    
            number z = (U - meanSum + correction) / sdSum

            // Calculate two-tailed probability value from normal distribution
            number p = 0
            if correction = 0.5
                p = 2.0 * zdistribution:CumulativeDistribution(z)
            elseif correction = -0.5
                p = 2.0 * (1.0 - zdistribution:CumulativeDistribution(z))
            else
                p = 2.0 * (1.0 - zdistribution:CumulativeDistribution(z))
            end
    
            // Calculate effect size
            number r = z / math:SquareRoot(N) 
    
            // Save the result
            CompareMeansResult result
            result:Ranked(true)
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            result:SetTestStatistic(combo, "U", U)
            result:SetEffectSize(combo, "Rosenthal's r", r)
            result:SetProbabilityValue(combo, "U", p)
            result:SetInformation(group1Text,"median", groupSummaries:Get(0):GetMedian())
            result:SetInformation(group1Text,"size", n1)
            result:SetInformation(group2Text,"median", groupSummaries:Get(1):GetMedian())
            result:SetInformation(group2Text,"size", n2)
            result:SetFormalTestName("Mann-Whitney U Test")
            result:SetGroupsFrame(groupFrame)
            result:SetFactors(factorHeaders)
            result:SetColumns(columnHeaders)
            results:Add(result)
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Friedman Test for 3 or more dependent groups.
        This can be used on 2 dependent groups, although the better option would be the Wilcoxon Signed-Ranks Test

        Null hypothesis: The population medians are equal across all samples.
        Alternative hypothesis: At least one population median is not equal to the others.
       
        Assumptions:
            1. Two or more related samples:
                If two samples: Best to use a Wilcoxon Signed-Ranks Test    > CompareMeans:CompareTwoRelatedRankedMeans
              
            2. Samples are dependent:
                If not dependent: Use a Kruskal-Wallis H-Test               > CompareMeans:CompareSeveralRankedMeans

            3. Samples are skewed, or not normally distributed:
                To test this: Use a Shapiro-Wilk test                       > CompareDistributions:CompareDistributionToNormal
                If not skewed: Use a One-Way Repeated-Measures Anova Test   > CompareMeans:CompareSeveralRelatedMeans

            4. Samples follow a similarly-shaped distribution
                To test this: Use a Kolmogorov-Smirnov Test                 >

        Post-Hoc Analysis:
            If this test is significant it may help to run a post hoc follow-up test
            This can be done using a CompareMeansPairwise test and passing the result from this test as the parameter
                Use a Bonferroni Pairwise Procedure                         > CompareMeansPairwise > UseStrictCorrection(true)

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("data.csv")        
        frame:AddSelectedColumnRange(0,3)
    
        CompareMeans compare = frame:CompareRelatedRankedMeans()
        output compare:GetSummary()
    */
    action CompareSeveralRelatedRankedMeans(DataFrame frame)
        ranked = true
        repeated = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 2
            alert("CompareSeveralRelatedRankedMeans must have at least two samples.")
        end
        if multivariate
            alert("A non-parametric multivariate n-sample repeated measures CompareMeans test is not supported yet.")
        elseif factorial
            alert("A non-parametric factorial n-sample repeated measures CompareMeans test is not supported yet.")
        else
            // Check sample sizes should be equal
            DataFrame groupFrame = design:GetGroupsFrame()
            integer sampleSize = 0
            integer i = 0
            repeat while i < groupFrame:GetSize()
                DataFrameColumn column = groupFrame:GetColumn(i)
                if i = 0
                    sampleSize = column:GetSize()
                else
                    if sampleSize not= column:GetSize()
                        alert("Samples must be the same size for a repeated design.")
                    end
                end
                if sampleSize < 2
                    alert("Samples must have 2 or more observations. Group "+column:GetHeader()+" has only "+column:GetSize()+" observations. Not enough data for a comparison to be calculated.")
                end       
                i = i + 1
            end

            // Rank the data for each subject (each column in rotated frame)
            DataFrame rankedLong = design:GetRankedFrame()
            rankedLong:EmptySelectedFactors()
            rankedLong:AddSelectedFactors(design:GetSubjectIdentifier())  

            TransformWider widen
            DataFrame ranked = widen:Transform(rankedLong)
            ranked:SelectAllColumns()    
            i = 0 
            repeat while i < ranked:GetSize()
                j = 0
                repeat while j < design:GetWithinSubjectsFactors():GetSize()
                    if ranked:GetColumn(i):GetHeader() = design:GetWithinSubjectsFactors():Get(j)
                        ranked:RemoveSelectedColumns(design:GetWithinSubjectsFactors():Get(j))
                    end
                    j = j + 1
                end
                i = i + 1
            end
            ranked = ranked:CopySelectedColumns()   
           
            // Number of subjects
            integer n = ranked:GetColumns():GetSize()
    
            // Number of measurements (groups)
            integer k = groups:GetSize()
    
            number sumOfRanksSquared = 0
            number tieCorrectionSum = 0
            // Get a rank sum for each group (sample) (each row in ranked frame)
            Array <number> rankSums
            i = 0
            repeat while i < n
                DataFrameColumn column = ranked:GetColumn(i)
                j = 0
                repeat while j < column:GetSize()
                    number rank = column:GetAsNumber(j)
                    if i = 0
                        rankSums:Add(rank)
                    else
                        rankSums:Set(j, rankSums:Get(j) + rank)
                    end
                    sumOfRanksSquared = sumOfRanksSquared + rank * rank
                    j = j + 1
                end
        
                // If ties occurred, apply adjustment later
                tieCorrectionSum = tieCorrectionSum + CalculateTieCorrectionSum(column)
                i = i + 1
            end
    
            // See T2 on page 12: https://www.osti.gov/servlets/purl/6057803
            // Calculate Q Statistic:
            number sumOfRankCalcsSquared = 0 
            number subtract = (n * (k + 1)) / 2.0
            i = 0
            repeat while i < k
                number value = rankSums:Get(i)
                sumOfRankCalcsSquared = sumOfRankCalcsSquared + (value - subtract) * (value - subtract)
                i = i + 1
            end  
            // There are other ways to do this, but this keeps the tie sum available for post hoc tests.
            number q = (12.0 / (n * k * (k + 1))) * sumOfRankCalcsSquared
            text ties = ""
            if tieCorrectionSum not= 0
                number d = 1 - (tieCorrectionSum / (n * k * (k * k - 1))) // The tie correction
                q = q / d
                ties = " with tie correction"
            end
            // See S2 on page 12: https://www.osti.gov/servlets/purl/6057803
            number variance = (1.0 / (k - 1.0)) * (sumOfRanksSquared - (n * k * (k + 1.0) * (k + 1.0) / 4.0)) // Used in post hoc calculation for Conovers test
        
            // Calculate probability value from chi-squared distribution
            number df = k-1
            x2distribution:Setup(df)
            number p = 1.0 - x2distribution:CumulativeDistribution(q)
    
            // Calculate effect size
            number kendalls_w = q / (n * (k -1))


            // Save the result
            CompareMeansResult result
            result:Ranked(true)
            result:Repeated(true)
            result:EqualVariances(AssumeEqualVariances())
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            Array<text> sources            
            // Measures
            text source = "Measures"
            if numberOfFactors = 1
                source = design:GetWithinSubjectsFactors():Get(0)
            end
            sources:Add(source)
            result:SetTestStatistic(source, "Friedman χ2", q)
            result:SetDegreesOfFreedom(source, "Friedman χ2", df)
            result:SetEffectSize(source, "Kendall's W", kendalls_w)
            result:SetProbabilityValue(source, "Friedman χ2", p)
            result:SetInformation(source,"size", sampleSize)
            result:SetInformation(source,"tie correction sum",tieCorrectionSum)
            result:SetInformation(source,"variance", variance)
            result:SetInformation(source,"df", df)
            result:SetInformation(source,"p",p)
            result:SetInformation(source,"x2", q)
            result:SetInformation(source,"kendalls w", kendalls_w) 
            result:SetFormalTestName("Friedman Test"+ties)
            result:SetGroupsFrame(groupFrame)
            result:SetFactors(factorHeaders)
            result:SetColumns(columnHeaders)
            result:SetSources(sources)
            if userRequestedPairwise or p <= GetSignificanceLevel()
                // Pairwise tests are only necessary if the test is significant
                CompareMeansPairwise compare
                compare:SetSignificanceLevel(GetSignificanceLevel())
                compare:SetStatisticalFormatting(GetStatisticalFormatting())
                compare:UseLenientCorrection(useLenientCorrection)
                compare:UseStrictCorrection(useStrictCorrection)
                compare:SetExperimentalDesign(design)
                compare:Calculate(result)
                result:SetPairwiseResults(compare:GetResults())
            end
            results:Add(result)
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    /* 
        Kruskal-Wallis H-Test for 3 or more independent groups.
        This can be used on 2 independent groups, although the better option would be the Mann-Whitney U Test

        Null hypothesis: The population medians are equal across all samples.
        Alternative hypothesis: At least one population median is not equal to the others.

        Assumptions:
            1. Two or more samples:
                If two samples: Best to use a Mann-Whitney U-Test   > CompareMeans:CompareTwoRankedMeans
              
            2. Samples are independent:
                If not independent: Use a Friedman Test             > CompareMeans:CompareSeveralRelatedRankedMeans

            3. Samples are skewed, or not normally distributed:
                To test this: Use a Shapiro-Wilk test               > CompareDistributions:CompareDistributionToNormal
                If not skewed: Use a One-Way Anova Test             > CompareMeans:CompareSeveralMeans

            4. Samples follow a similarly-shaped distribution
                To test this: Use a Kolmogorov-Smirnov Test         >

        Post-Hoc Analysis:
            If this test is significant it may help to run a post hoc follow-up test
            This can be done using a CompareMeansPairwise test and passing the result from this test as the parameter
                Use a Dunn's Multiple Comparison Test               > CompareMeansPairwise > UseLenientCorrection(true)

        Attribute: Example
    
        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:AddSelectedColumnRange(0,3)
    
        CompareMeans compare = frame:CompareRankedMeans()
        output compare:GetSummary()
    */
    action CompareSeveralRankedMeans(DataFrame frame)
        ranked = true
        if needToProcessData or design = undefined
            needToSelectTest = false  // This test has been selected (skip RunTest)
            me:Calculate(frame)
        end
        if groups:GetSize() < 2
            alert("CompareSeveralRankedMeans must have at least two samples.")
        end
        if factorial
            alert("A non-parametric factorial several-sample CompareMeans test is not supported yet.")
        end
        if multivariate
            alert("A non-parametric multivariate several-sample CompareMeans test is not supported yet.")
        else
            // Check sample sizes should be at least 2
            DataFrame groupFrame = design:GetGroupsFrame()
            integer sampleSize = 0
            integer i = 0
            repeat while i < groupFrame:GetSize()
                DataFrameColumn column = groupFrame:GetColumn(i)
                if column:GetSize() < 2
                    alert("Samples must have 2 or more observations. Group "+column:GetHeader()+" has only "+column:GetSize()+" observations. Not enough data for a comparison to be calculated.")
                end       
                i = i + 1
            end

            // Rank the data all a whole and get groups
            DataFrame rankedLong = design:GetRankedFrame()
            DataFrame rankedGroupsFrame = rankedLong:CreateNewDataFrameFromFactoredColumns()
            rankedGroupsFrame:SelectAllColumns()
            Array<Summarize> groupSummaries = rankedGroupsFrame:SummarizeSelectedColumns()

            number sumOfRanksSquared = 0
            i = 0
            repeat while i < groupSummaries:GetSize()
                sumOfRanksSquared = sumOfRanksSquared + groupSummaries:Get(i):GetSumOfSquares()
                i = i + 1
            end         

            // See page 10: https://www.osti.gov/servlets/purl/6057803
            // Calculate the H statistic:
            number n = design:GetNumberOfObservations() // Overall size (all sample sizes)
            integer k = groupFrame:GetSize()            // Number of samples
            number sumOfRanksSquaredMean = 0
            j = 0
            repeat while j < k
                number tj = groupSummaries:Get(j):GetSum()                                                  // Sum of ranks in the jth sample
                number nj = groupFrame:GetColumn(j):GetSize() - groupFrame:GetColumn(j):GetUndefinedSize()  // Size of the jth sample
    
                sumOfRanksSquaredMean = sumOfRanksSquaredMean + (tj * tj / nj)
                j = j + 1
            end
            number h = (12.0 / (n * (n + 1))) * sumOfRanksSquaredMean - (3 * (n + 1)) 
            number variance = (1.0 / (n - 1.0)) * (sumOfRanksSquared - (n * (n + 1.0) * (n + 1.0) / 4.0)) // Used in post hoc calculation for Conovers test
    
            // Correct for ties in ranking. There are other ways to do this but this keeps the tie sum available for post hoc tests.
            // See: https://www.dataanalytics.org.uk/adjustment-for-tied-ranks-in-the-kruskal-wallis-test/
            text ties = ""
            number tieCorrectionSum = CalculateTieCorrectionSum(rankedLong:GetColumn(design:GetDependentVariables():Get(0)))
            if tieCorrectionSum not= 0
                number d = 1 - (tieCorrectionSum / ((n - 1) * n * (n + 1))) // The tie correction
                h = h / d
                ties = " with tie correction"
            end

            // Calculate probability value from chi-squared distribution
            number df = k-1
            x2distribution:Setup(df)
            number p = 1.0 - x2distribution:CumulativeDistribution(h)
    
            // Calculate effect size
            number eta_sqr = (h - k + 1) / (n - k)
            number epsilon_sqr = h * (n + 1) / (n * n - 1)


            // Save the result
            CompareMeansResult result
            result:Ranked(true)
            result:EqualVariances(AssumeEqualVariances())
            result:SetSignificanceLevel(GetSignificanceLevel())
            result:SetFormat(GetStatisticalFormatting())
            Array<text> sources            
            // Between Measures
            text source = "Groups"
            if numberOfFactors = 1
                source = design:GetBetweenSubjectsFactors():Get(0)
            end
            sources:Add(source)
            result:SetTestStatistic(source, "H", h)
            result:SetDegreesOfFreedom(source, "H", df)
            result:SetEffectSize(source, "epsilon-squared", epsilon_sqr)
            result:SetProbabilityValue(source, "H", p)
            result:SetInformation(source,"size", sampleSize)
            result:SetInformation(source,"tie correction sum",tieCorrectionSum)
            result:SetInformation(source,"variance",variance)
            result:SetInformation(source,"epsilon-squared", epsilon_sqr)
            result:SetInformation(source,"eta-squared", eta_sqr)
            result:SetInformation(source,"p", p)
            result:SetInformation(source,"H", h)
            result:SetInformation(source,"df", df)
            result:SetFormalTestName("Kruskal-Wallis Test"+ties)
            result:SetGroupsFrame(groupFrame)
            result:SetFactors(factorHeaders)
            result:SetColumns(columnHeaders)
            result:SetSources(sources)
            if userRequestedPairwise or p <= GetSignificanceLevel()
                // Pairwise tests are only necessary if the test is significant
                CompareMeansPairwise compare
                compare:SetSignificanceLevel(GetSignificanceLevel())
                compare:SetStatisticalFormatting(GetStatisticalFormatting())
                compare:UseLenientCorrection(useLenientCorrection)
                compare:UseStrictCorrection(useStrictCorrection)
                compare:SetExperimentalDesign(design)
                compare:Calculate(result)
                result:SetPairwiseResults(compare:GetResults())
            end
            results:Add(result)
        end
        needToProcessData = true // Reset processing flag in case user changes selections
    end

    action SetExperimentalDesign(ExperimentalDesign design)
        me:design = design:Copy() // make a copy of the design so it can be used in other tests.
    end

    // This is the class that holds all design selections and design frame.
    action GetDesign returns ExperimentalDesign
        return design
    end

    // For long or wide data.
    action AddSubjectIdentifier(text header)
        design:AddSubjectIdentifier(header)
    end

    // For long or wide data.
    action AddBetweenSubjectsFactor(text header)
        design:AddBetweenSubjectsFactor(header)
    end

    // For long data.
    action AddWithinSubjectsFactor(text header)
        design:AddWithinSubjectsFactor(header)
    end

    // For long data.
    action AddDependentVariable(text header)
        design:AddDependentVariable(header)
    end

    // For wide data in between design.
    action AddBetweenSubjectsFactor(text factorHeader, text variableHeader, text columnHeaders)
        design:AddBetweenSubjectsFactor(factorHeader, variableHeader, columnHeaders)
    end

    // For wide data in between design.
    action AddBetweenSubjectsFactor(text factorHeader, text columnHeaders)
        design:AddBetweenSubjectsFactor(factorHeader, columnHeaders)
    end

    // For wide data in within design or mixed design.
    action AddWithinSubjectsFactor(text factorHeader, text variableHeader, text columnHeaders)
        design:AddWithinSubjectsFactor(factorHeader, variableHeader, columnHeaders)
    end

    // For wide data in within design or mixed design.
    action AddWithinSubjectsFactor(text factorHeader, text columnHeaders)
        design:AddWithinSubjectsFactor(factorHeader, columnHeaders)
    end

    /* Used in 1-sample and 2-sample (paired) tests */
    action SetMean(number mean)
        me:userMean = mean
        me:userMedian = mean
    end

    /* Used in 1-sample and 2-sample (paired) rank tests */
    action SetMedian(number median)
        me:userMedian = median
        me:userMean = median
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action Ranked(boolean ranked)
        me:ranked = ranked
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action Ranked returns boolean
        return ranked
    end

    /* Used in 2-sample tests */
    action Paired(boolean paired)
        me:repeated = paired
    end

    /* Used in 2-sample tests */
    action Paired returns boolean
        return repeated
    end

    /* Used in N-sample tests */
    action RepeatedMeasures(boolean repeatedMeasures)
        me:repeated = repeatedMeasures
    end

    /* Used in N-sample tests */
    action RepeatedMeasures returns boolean
        return repeated
    end

    /* Used in 2-sample and N-sample tests */
    action AssumeEqualVariances(boolean assume)
        assumeEqualVariances = assume
        if assume
            testVarianceAssumption = false
        end
        defaultVarianceAssumption = false
    end

    /* Used in 2-sample and N-sample tests */
    action AssumeEqualVariances returns boolean
        return assumeEqualVariances or defaultVarianceAssumption
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action AssumeNormalDistribution(boolean assume)
        assumeNormalDistribution = assume
        if assume
            testDistributionAssumption = false
        end
        defaultDistributionAssumption = false
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action AssumeNormalDistribution returns boolean
        return assumeNormalDistribution or defaultDistributionAssumption
    end

    /* Used in N-sample tests */
    action TestPairwise
        userRequestedPairwise = true
    end

    /* Used in 2-sample and N-sample tests */
    action TestVarianceAssumption
        testVarianceAssumption = true
        assumeEqualVariances = false
    end

    /* Used in 1-sample, 2-sample, and N-sample tests */
    action TestDistributionAssumption
        testDistributionAssumption = true
        assumeNormalDistribution = false
    end

    /* This action will set all of the relevant assumption tests to be calculated */
    action TestAllAssumptions
        TestVarianceAssumption()
        TestDistributionAssumption()
    end

    /* Conservative method is the default for most tests if another is not selected */
    action CorrectFamilyWiseError(boolean correctFamilyWiseError)
        me:correctFamilyWiseError = correctFamilyWiseError
        if not useLenientCorrection
            useStrictCorrection = correctFamilyWiseError
        end
    end

    /* Choose strict pairwise comparison as correction for N-sample pairwise tests */
    action UseStrictCorrection(boolean useStrictCorrection)
        correctFamilyWiseError = useStrictCorrection
        me:useStrictCorrection = useStrictCorrection
        if useStrictCorrection
            useLenientCorrection = false
        end
    end

    /* Choose lenient multiple comparison as correction for N-sample pairwise tests */
    action UseLenientCorrection(boolean useLenientCorrection)
        correctFamilyWiseError = useLenientCorrection
        me:useLenientCorrection = useLenientCorrection
        if useLenientCorrection
            useStrictCorrection = false
        end
    end

    /* Returns true for correction */
    action CorrectFamilyWiseError returns boolean
        return correctFamilyWiseError
    end

    /* Returns true for strict pairwise comparison as correction for N-sample pairwise tests */
    action UsingStrictCorrection returns boolean
        return useStrictCorrection
    end

    /* Returns true for lenient multiple comparison as correction for N-sample pairwise tests */
    action UsingLenientCorrection returns boolean
        return useLenientCorrection
    end

    /* Returns true for multiple comparisons to use the model as a reference for N-sample pairwise tests */
    action UsingFittedApproach returns boolean
        return useFittedApproach
    end

    /* Choose fitted (unplanned) approach pairwise comparisons for N-sample pairwise tests */
    action UseFittedApproach(boolean useFittedApproach)
        me:useFittedApproach = useFittedApproach
        me:useUnfittedApproach = not useFittedApproach
    end

    /* Returns true for multiple comparisons to use individual tests for N-sample pairwise tests */
    action UsingUnfittedApproach returns boolean
        return useUnfittedApproach
    end

    /* Choose unfitted (planned) approach pairwise comparisons for N-sample pairwise tests */
    action UseUnfittedApproach(boolean useUnfittedApproach)
        me:useUnfittedApproach = useUnfittedApproach
        me:useFittedApproach = not useUnfittedApproach
    end

    /*
        This returns the probability if only one result exists.

        Attribute: Returns the P-Value. 
    */
    action GetProbabilityValue returns number
        return GetResult():GetProbabilityValue()
    end

    /*
        This returns the probabilities of all results in a dataframe

        Attribute: Returns the probability frame
    */  
    action GetProbabilities returns DataFrame
        return GenerateProbabilityDataFrame()        
    end

    /*
        This returns the degrees of freedom if only one result exists.

        Attribute: Returns the Degrees of Freedom. 
    */
    action GetDegreesOfFreedom returns number
        return GetResult():GetDegreesOfFreedom()
    end

    /*
        This returns the test statistic if only one result exists.

        Attribute: Returns the test statistic. 
    */
    action GetTestStatistic returns number
        return GetResult():GetTestStatistic()
    end

    /*
        This returns the effect size if only one result exists.

        Attribute: Returns the effect size. 
    */
    action GetEffectSize returns number
        return GetResult():GetEffectSize()
    end

    /*
        This returns the distribution assumption test results if only one result exists.
        If no distribution tests were conducted, this will return undefined.

        Attribute: Returns the distribution results. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
        use Libraries.Compute.Statistics.Reporting.CompareDistributionsResult
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestDistributionAssumption()
        frame:Calculate(compare)

        Array<CompareDistributionsResult> dResults = compare:GetDistributionResults()
    */
    action GetDistributionResults returns Array<CompareDistributionsResult>
        return GetResult():GetDistributionResults()
    end

    /*
        This returns the variance assumption test result if only one result exists.
        If no variance tests were conducted, this will return undefined.

        Attribute: Returns the variance result. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
        use Libraries.Compute.Statistics.Reporting.CompareVariancesResult
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestVarianceAssumption()
        frame:Calculate(compare)

        CompareVariancesResult vResult = compare:GetVarianceResult() 
    */
    action GetVarianceResult returns CompareVariancesResult
        return GetResult():GetVarianceResult()
    end

    /*
        This returns the pairwise results if only one result exists.
        Pairwise results are only calculated in N-sample tests, 
        otherwise this will return undefined.

        Attribute: Returns the pairwise results. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
        use Libraries.Compute.Statistics.Reporting.CompareMeansResult
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestPairwise()
        frame:Calculate(compare)

        Array<CompareMeansResult> pairwise = compare:GetPairwiseResults() 
    */
    action GetPairwiseResults returns Array<CompareMeansResult>
        return GetResult():GetPairwiseResults()
    end

    /*
        This returns the assumption test summary if only one result exists.
        If no assumption tests were conducted, this will return nothing.

        Attribute: Returns the assumption test summary. 
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestAllAssumptions()
        frame:Calculate(compare)

        output compare:GetAssumptionTestSummary() 
    */
    action GetAssumptionTestSummary returns text
        return GetResult():GetAssumptionTestSummary()
    end

    /*
        This returns the pairwise summary if only one result exists.
        Pairwise results are only calculated in N-sample tests, 
        otherwise this will return nothing.

        Attribute: Returns the pairwise summary.
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        compare:Add(2)
        compare:Add(3)
        compare:TestPairwise()
        frame:Calculate(compare)

        output compare:GetPairwiseSummary() 
    */
    action GetPairwiseSummary returns text
        return GetResult():GetPairwiseSummary()
    end

    /*
        This returns a result if only one exists.

        Attribute: Returns the CompareMeansResult object
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")

        CompareMeans compare
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:Calculate(frame)
        
        CompareMeansResult result = compare:GetResult()
    */
    action GetResult returns CompareMeansResult
        if GetResults():GetSize() = 0
            alert("There are no results calculated")
        elseif GetResults():GetSize() = 1
            return GetResults():Get(0)
        else
            alert("There is more than one test result, use GetResults() for an array of all results")
        end
    end

    /*
        Attribute: Returns an array of CompareMeansResult objects
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:AddColumn(0)
        compare:AddColumn(1)
        compare:AddColumn(2)
        frame:Calculate(compare)

        Array<CompareMeansResult> results = compare:GetResults()
    */
    action GetResults returns Array<CompareMeansResult>
        return results
    end

    /*
        Attribute: Returns a list of the important statistics of the test
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        frame:Calculate(compare)

        output compare:GetSummary()
    */
    action GetSummary returns text
        text summary = ""
        text lf = summary:GetLineFeed()
        i = 0
        CompareMeansResult result 
        repeat while i < GetResults():GetSize()
            result = GetResults():Get(i)

            summary = summary + lf
            summary = summary + result:GetSummary()
            summary = summary + lf
            i = i + 1
        end

        return summary
    end

    /*
        Attribute: Returns a DataFrame of the important statistics of the test
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        frame:Calculate(compare)
        
        DataFrame result = compare:GetSummaryDataFrame()
        result:Save("myresult.csv")
    */
    action GetSummaryDataFrame returns DataFrame
        if GetResults():GetSize() = 1
            return GetResult():GetSummaryDataFrame()
        end

        return GetMultipleTestSummaryDataFrame()
    end

    /*
        This action summarizes the results and places them into formal academic language, in 
        APA format.
        For more information: https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf

        Attribute: Returns a condensed formal result of the test
        Attribute: Example

        use Libraries.Compute.Statistics.DataFrame
        use Libraries.Compute.Statistics.Tests.CompareMeans
    
        DataFrame frame
        frame:Load("Data/Data.csv")
    
        CompareMeans compare
        compare:Add(0)
        compare:Add(1)
        frame:Calculate(compare)

        output compare:GetFormalSummary()
    */
    action GetFormalSummary returns text
        text summary = ""
        text lf = summary:GetLineFeed()
        i = 0
        CompareMeansResult result 
        repeat while i < GetResults():GetSize()
            result = GetResults():Get(i)

            summary = summary + lf
            summary = summary + result:GetFormalSummary()
            summary = summary + lf
            i = i + 1
        end
        return summary
    end

    /* PRIVATE ACTIONS */
    /************************************************************************************/
    /************************************************************************************/


    /* Data pre-processing and checking action */
    /************************************************************************************/

    private action CopySelection(DataFrame frame)
        if frame:GetSelection() not= undefined
            frame:GetSelection():CopyTo(cast(ColumnInput, me))
        end
        if frame:GetSelection() not= undefined 
            frame:GetSelection():CopyTo(cast(FactorInput, me))
        end
    end

    private action CheckDataIntegrity(DataFrame frame)
        i = 0
        repeat while i < frame:GetSelectedColumnSize()
            DataFrameColumn column = frame:GetColumn(frame:GetSelection():GetColumn(i))
    
            if column:IsUndefined()
                alert("Column is undefined.")
            end
            if not column:IsNumberColumn() and not column:IsIntegerColumn()
                alert("Columns must be numerical. " + column:GetHeader() + " is not a numerical column.")
            end
            if column:GetSize() < 2
                alert("Columns must have 2 or more entries. Not enough data for comparison to be calculated.")
            end
            i = i + 1
        end
    end

    // Checks if all sample sizes are equal.
    private action CheckIfBalanced returns boolean
        integer firstSize = 0
        Array<DataFrame> groupsArray = groups:CopyToValueArray()
        i = 0 
        repeat while i < groupsArray:GetSize()
            if i = 0
                firstSize = groupsArray:Get(i):GetColumn(0):GetSize()
            else
                if groupsArray:Get(i):GetColumn(0):GetSize() not= firstSize
                    return false
                end
            end
            i = i + 1
        end
        return true
    end


    /* Test computation helper actions */
    /************************************************************************************/

    /* Computes approximate degrees of freedom for 2-sample t-test in unranked Compare2Groups */
    private action DegreesOfFreedom(number variance1, number variance2, number size1, number size2) returns number
        return (((variance1 / size1) + (variance2 / size2)) * ((variance1 / size1) + (variance2 / size2))) /
        ((variance1 * variance1) / (size1 * size1 * (size1 - 1.0)) + (variance2 * variance2) /
                (size2 * size2 * (size2 - 1.0)))
    end

    /* Calculates the sum portion of the tie corrections for each of the ranked tests in this class. Returns: Σ (t^3 - t) */
    private action CalculateTieCorrectionSum(DataFrameColumn ranks) returns number
        number sum = 0
        DataFrameColumn count = ranks:Copy()
        HashTable<text,integer> hash = count:CalculateValueCountAsText()
        Iterator<integer> i = hash:GetValueIterator()
        integer result = 0
        repeat while i:HasNext()
            result = i:Next()
            sum = sum + (result * result * result - result)
            if result > 1
                rankTiesWarning = true
            end
        end
        return sum
    end

    private action GetInitialEncoding(integer size) returns Matrix
        Matrix matrix
        matrix:Fill(1,size,0)
        return matrix
    end

    private action GetInitialMatrix() returns Matrix
        integer sum = 1
        integer prod = 1
        i = 0 
        repeat while i < factorLevels:GetSize()
            prod = prod * factorLevels:Get(i):GetSize()
            i = i + 1
        end
        integer rows = totalObservations
        integer cols = prod

        Matrix initial
        initial:Fill(rows, cols, 0)
        initial:SetColumn(0, 1)

        i = 0
        repeat while i < initial:GetColumns()
            factorsAssociatedWithColumn:Add(i, GetInitialEncoding(factorLevels:GetSize()))
            i = i + 1
        end
        return initial
    end

    private action AddFactorsToDesignMatrix(DataFrame frame, Matrix designMatrix) returns integer 
        if designFrame:GetSelectedFactorSize() = 1
            j = 0 
            repeat while j < factorLevels:Get(0):GetSize() - 1
                text level = factorLevels:Get(0):GetAsText(j)
                DataFrameColumn factor = frame:GetColumn(frame:GetSelection():GetFactor(0))
                k = 0
                repeat while k < factor:GetSize()
                    if factor:GetAsText(k) = level
                        designMatrix:Set(k, j+1, 1)
                    end
                    k = k + 1
                end 
                text factorHeader = factor:GetHeader()
                if not columnsAssociatedWithFactor:HasKey(factorHeader)
                    Array<integer> arr
                    arr:Add(j+1)
                    columnsAssociatedWithFactor:Add(factorHeader, arr)
                else
                    columnsAssociatedWithFactor:GetValue(factorHeader):Add(j+1)
                end
                factorsAssociatedWithColumn:GetValue(j+1):Set(0, factorIndex:GetKey(factorHeader), 1)
                j = j + 1
            end
            return 0
        else
            integer current = 1
            integer reset = current
            i = 0 
            repeat while i < factorLevels:GetSize()
                j = 0 
                repeat while j < factorLevels:Get(i):GetSize() - 1
                    text level = factorLevels:Get(i):GetAsText(j)
                    DataFrameColumn factor = frame:GetColumn(frame:GetSelection():GetFactor(i))
                    k = 0
                    repeat while k < factor:GetSize()
                        if factor:GetAsText(k) = level
                            designMatrix:Set(k, current, 1)
                        end
                        k = k + 1
                    end 
                    text factorHeader = factor:GetHeader()
                    if not columnsAssociatedWithFactor:HasKey(factorHeader)
                        Array<integer> arr
                        arr:Add(current)
                        columnsAssociatedWithFactor:Add(factorHeader, arr)
                    else
                        columnsAssociatedWithFactor:GetValue(factorHeader):Add(current)
                    end
                    factorsAssociatedWithColumn:GetValue(current):Set(0, factorIndex:GetKey(factorHeader), 1)
                    current = current + 1
                    j = j + 1
                end
                current = reset + (factorLevels:Get(i):GetSize() - 1)
                reset = current
    
                i = i + 1
            end
            return current
        end
    end

    private action AddInteractionsToDesignMatrix(Matrix designMatrix, integer reset, integer start, integer next, integer stop, integer current)
        if current > designMatrix:GetColumns() - 1
            return now
        end

        if not AlreadyAssociated(next, start)
            // Check previous associations too
            boolean previouslyAssociated = false
            if start > 1 and reset >= start
                i = start
                repeat while i >= 1
                    if AlreadyAssociated(next, i)
                        previouslyAssociated = true
                    end
                    i = i - 1
                end
            end
            if not previouslyAssociated
                AssociateFactorsOfOldColumnToNewColumn(start, next, current)
                designMatrix:SetColumn(current, designMatrix:GetColumn(start):MultiplyElements(designMatrix:GetColumn(next)))
                current = current + 1
            end
        end
        if next = stop
            start = start + 1
            if start = stop
                reset = stop
                start = 1
                stop = current - 1
            end
            if reset < start
                next = start + 1
            else
                next = reset + 1
            end
        else
            next = next + 1
        end
        AddInteractionsToDesignMatrix(designMatrix, reset, start, next, stop, current)
    end

    private action AlreadyAssociated(integer nextAssociation, integer currAssociation) returns boolean
        Matrix nextFactors = factorsAssociatedWithColumn:GetValue(nextAssociation)
        Matrix currFactors = factorsAssociatedWithColumn:GetValue(currAssociation)

        if nextFactors not= undefined and currFactors not= undefined
            i = 0
            repeat while i < currFactors:GetColumns()
                if currFactors:Get(0, i) = 1 and nextFactors:Get(0, i) = 1
                    return true
                end
                i = i + 1
            end
        end
        return false
    end

    private action AssociateFactorsOfOldColumnToNewColumn(integer firstIndex, integer secondIndex, integer newIndex)
        Matrix factors1 = factorsAssociatedWithColumn:GetValue(firstIndex)
        Matrix factors2 = factorsAssociatedWithColumn:GetValue(secondIndex)  

        if factors1 not= undefined and factors2 not= undefined  
            Matrix newFactor = factors1:AddElements(factors2)
            factorsAssociatedWithColumn:Set(newIndex, newFactor)

            text factorHeader = GetTextFromEncoding(newFactor)
            if not columnsAssociatedWithFactor:HasKey(factorHeader)
                Array<integer> arr
                arr:Add(newIndex)
                columnsAssociatedWithFactor:Add(factorHeader, arr)
            else
                columnsAssociatedWithFactor:GetValue(factorHeader):Add(newIndex)
            end
        end
    end

    private action GetTextFromEncoding(Matrix factorEncoding) returns text
        text factorText = ""
        j = 0
        repeat while j < factorEncoding:GetColumns()
            integer activation = cast(integer, factorEncoding:Get(0,j))
            if activation = 1
                if factorText = "" 
                    factorText = factorIndex:GetValue(j)
                else
                    factorText = factorText + ":" + factorIndex:GetValue(j) 
                end
            end
            j = j + 1
        end
        return factorText
    end

    private action GetDegreesOfFreedomFromEncoding(Matrix factorEncoding) returns number
        number degreesOfFreedom = 1
        j = 0
        repeat while j < factorEncoding:GetColumns()
            integer activation = cast(integer, factorEncoding:Get(0,j))
            if activation = 1 
                factorText = factorIndex:GetValue(j)
                degreesOfFreedom = degreesOfFreedom * (factorLevels:Get(j):GetSize() - 1)
            end
            j = j + 1
        end
        return degreesOfFreedom
    end

    private action ComputeSumOfSquares(Matrix x, Matrix y) returns number
        Matrix xT = x:Transpose()
        Matrix xTx_inv = xT:Multiply(x):Inverse()  
        Matrix b = xTx_inv:Multiply(xT):Multiply(y)       
             
        Matrix result = y:SubtractElements(x:Multiply(b))

        return result:GetSumOfSquares()
    end


    private action ComputeSumOfSquaresCrossProductMatrix(Matrix x, Matrix y) returns Matrix
        Matrix xT = x:Transpose()
        Matrix xTx_inv = xT:Multiply(x):Inverse()       
        Matrix b = xTx_inv:Multiply(xT):Multiply(y)          
        Matrix result = y:SubtractElements(x:Multiply(b))

        Matrix centered = result:CenterByColumn()
        return centered:Transpose():Multiply(centered)
    end


    private action AddMatching(Matrix factorEncoding, Matrix designMatrix, Matrix withoutMatrix) returns Matrix
        Matrix newMatrix
        newMatrix:SetSize(designMatrix)

        integer colIndex = 0
        i = 0
        repeat while i < withoutMatrix:GetColumns()
            newMatrix:SetColumn(colIndex, withoutMatrix:GetColumn(i))
            colIndex = colIndex + 1
            i = i + 1
        end

        i = 0
        repeat while i < designMatrix:GetColumns()
            Matrix columnFactors = factorsAssociatedWithColumn:GetValue(i) 
            boolean same = true
            j = 0 
            repeat while j < columnFactors:GetColumns()
                if columnFactors:Get(0, j) not= factorEncoding:Get(0, j)
                    same = false
                end
                j = j + 1
            end

            if same
                newMatrix:SetColumn(colIndex, designMatrix:GetColumn(i))
                colIndex = colIndex + 1
            end
  
            i = i + 1
        end
        return newMatrix:GetSubMatrix(0, 0, designMatrix:GetRows(), colIndex)
    end

    private action RemoveAssociated(Matrix factorEncoding, Matrix designMatrix) returns Matrix
        Matrix newMatrix
        newMatrix:SetSize(designMatrix)
        integer colIndex = 0
        integer count = cast(integer, factorEncoding:GetTotal())
        i = 0
        repeat while i < designMatrix:GetColumns()
            integer samecount = 0
            Matrix columnFactors = factorsAssociatedWithColumn:GetValue(i)
            j = 0 
            repeat while j < columnFactors:GetColumns()
                if columnFactors:Get(0, j) = 1 and factorEncoding:Get(0, j) = 1
                    samecount = samecount + 1
                end
                j = j + 1
            end            

            if samecount not= count
                newMatrix:SetColumn(colIndex, designMatrix:GetColumn(i))
                colIndex = colIndex + 1
            end
            i = i + 1
        end
        return newMatrix:GetSubMatrix(0, 0, designMatrix:GetRows(), colIndex)
    end

    /* This is used to update the correct residual ss and df values for mixed design anovas */
    private action UpdateAndGetErrorTerm(HashTable<text, number> ssErrors, HashTable<text, number> dfErrors, text interactionFactor, number ssInteraction, number dfInteraction) returns text
        Array<text> factors = interactionFactor:Split(":")
        Array<text> withinFactors = design:GetWithinSubjectsFactors()
        text errorFactor = ""
        i = 0
        repeat while i < factors:GetSize()
            j = 0
            repeat while j < withinFactors:GetSize()
                if factors:Get(i) = withinFactors:Get(j)
                    if errorFactor = ""
                        errorFactor = factors:Get(i)
                    else
                        errorFactor = errorFactor+":"+factors:Get(i)
                    end
                end
                j = j + 1
            end
            i = i + 1
        end
        if ssErrors:HasKey(errorFactor)
            ssErrors:Set(errorFactor, ssErrors:GetValue(errorFactor) - ssInteraction)
            dfErrors:Set(errorFactor, dfErrors:GetValue(errorFactor) - dfInteraction)
            return errorFactor
        else
            ssErrors:Set(design:GetSubjectIdentifier(), ssErrors:GetValue(design:GetSubjectIdentifier()) - ssInteraction)
            dfErrors:Set(design:GetSubjectIdentifier(), dfErrors:GetValue(design:GetSubjectIdentifier()) - dfInteraction)
            return design:GetSubjectIdentifier()
        end
    end

    /* Reporting helper actions */
    /************************************************************************************/

    private action GetMultipleTestSummaryDataFrame returns DataFrame
        // Combine all the data frames into one, useful for pairwise or post hoc tests
        DataFrame full
        
        i = 0
        repeat while i < results:GetSize()
            if i = 0
                full = results:Get(i):GetSummaryDataFrame():Copy()
            else
                DataFrame summary = results:Get(i):GetSummaryDataFrame()
                j = 0
                repeat while j < full:GetSize() and j < summary:GetSize()
                    DataFrameColumn column = summary:GetColumn(j)
                    k = 0
                    repeat while k < column:GetSize()
                        full:GetColumn(j):Add(column:GetAsText(k))
                        k = k + 1
                    end
                    j = j + 1
                end
            end
            i = i + 1
        end
        return full
    end

    private action GenerateProbabilityDataFrame returns DataFrame
        integer digits = GetStatisticalFormatting():GetSignificantDigits()
        DataFrame frame
        HashTable <text, integer> index
        integer nextIndex = 0
        TextColumn rowHeaders
        frame:AddColumn(rowHeaders)
        i = 0
        CompareMeansResult result 
        repeat while i < GetResults():GetSize()
            result = GetResults():Get(i)
            if result:GetGroupsFrame():GetSize() = 1
                text grp1 = result:GetGroupsFrame():GetColumn(0):GetHeader()
                if not index:HasKey(grp1)
                    number value = result:GetProbabilityValue()
                    NumberColumn col1
                    col1:SetHeader(grp1)
                    col1:Add(math:Round(value, digits))
                    frame:AddColumn(col1)  
                    index:Add(grp1, nextIndex)
                    nextIndex = nextIndex + 1
                end
            elseif result:GetGroupsFrame():GetSize() = 2
                text grp1 = result:GetGroupsFrame():GetColumn(0):GetHeader()
                text grp2 = result:GetGroupsFrame():GetColumn(1):GetHeader()
                if not index:HasKey(grp1)
                    NumberColumn col1
                    col1:SetHeader(grp1)
                    col1:SetSize(GetResults():GetSize())
                    rowHeaders:Add(grp1)
                    frame:AddColumn(col1)  
                    index:Add(grp1, nextIndex)
                    nextIndex = nextIndex + 1
                end
                if not index:HasKey(grp2)
                    NumberColumn col2
                    col2:SetHeader(grp2)
                    col2:SetSize(GetResults():GetSize())
                    rowHeaders:Add(grp2)
                    frame:AddColumn(col2)  
                    index:Add(grp2, nextIndex)
                    nextIndex = nextIndex + 1
                end
                number value = result:GetProbabilityValue()
                frame:GetColumn(grp1):SetAsNumber(index:GetValue(grp1), 1.0)
                frame:GetColumn(grp2):SetAsNumber(index:GetValue(grp2), 1.0)

                frame:GetColumn(grp1):SetAsNumber(index:GetValue(grp2), math:Round(value, digits))
                frame:GetColumn(grp2):SetAsNumber(index:GetValue(grp1), math:Round(value, digits))
            else
                j = 0
                repeat while j < result:GetSources():GetSize()
                    text source = result:GetSources():Get(j)
                    if not index:HasKey(source)
                        if result:GetTestStatisticsTable():HasKey(source)
                            text statName = source
                            if not result:HasEqualVariances() or multivariate
                                statName = result:GetTestStatisticsTable():GetValue(source):GetKeyIterator():Next()                            
                            end
                            number value = result:GetProbabilityValuesTable():GetValue(source):GetValue(source)
                            NumberColumn col1
                            col1:SetHeader(source)
                            col1:Add(math:Round(value, digits))
                            frame:AddColumn(col1)  
                            index:Add(source, nextIndex)
                            nextIndex = nextIndex + 1
                        end
                    end
                    j = j + 1
                end
            end
            i = i + 1
        end
        rowHeaders:SetHeader("Probability")
        return frame:RemoveUndefinedRows()
    end
end

